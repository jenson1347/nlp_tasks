{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8255b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize as nltk_word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d29b92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('prc_1.csv')\n",
    "df = df.rename(columns={'text_type':'target'})\n",
    "df.target = df.target.astype('category')\n",
    "df.target = df.target.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2396364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>naturally irresistible your corporate identity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>the stock trading gunslinger fanny is merrill ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>unbelievable new homes made easy im wanting to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4 color printing special request additional in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>do not have money get software cds from here s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       1  naturally irresistible your corporate identity...\n",
       "1       1  the stock trading gunslinger fanny is merrill ...\n",
       "2       1  unbelievable new homes made easy im wanting to...\n",
       "3       1  4 color printing special request additional in...\n",
       "4       1  do not have money get software cds from here s..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733ca119",
   "metadata": {},
   "source": [
    "TF-IDF + Naive Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a8fbc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b06324d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lower(text):\n",
    "    return text.lower()\n",
    "def remove_punctuations(text):\n",
    "    return re.sub(r'[^\\w\\s]', '', text)\n",
    "def to_tokenize(text):\n",
    "    return nltk_word_tokenize(text)\n",
    "def remove_stopwords(tokens):\n",
    "    return [word for word in tokens if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47ea7da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def lemmatize(tokens):\n",
    "    return [morph.parse(word)[0].normal_form for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6623a420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(text,do_lemmatize = False):\n",
    "    text = to_lower(text)\n",
    "    text = remove_punctuations(text)\n",
    "    tokens = to_tokenize(text)\n",
    "    tokens = remove_stopwords(tokens)\n",
    "    if do_lemmatize == 0:\n",
    "        tokens = lemmatize(tokens)\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55d25ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20348/20348 [00:06<00:00, 3143.05it/s]\n"
     ]
    }
   ],
   "source": [
    "text = list(df.text)\n",
    "processed_text = []\n",
    "\n",
    "for t in tqdm(text):\n",
    "    processed_text.append(text_processing(t))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "662ed005",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'processed_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n\u001b[1;32m      3\u001b[0m tfidf_vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer()\n\u001b[0;32m----> 4\u001b[0m tfidf_matrix \u001b[38;5;241m=\u001b[39m tfidf_vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mprocessed_text\u001b[49m)\n\u001b[1;32m      6\u001b[0m tfidf_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(tfidf_matrix\u001b[38;5;241m.\u001b[39mtoarray(), columns\u001b[38;5;241m=\u001b[39mtfidf_vectorizer\u001b[38;5;241m.\u001b[39mget_feature_names_out())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'processed_text' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(processed_text)\n",
    "\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53ef5da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9603bb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultinomialNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(tfidf_df,df.target,test_size=0.3)\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a4de8857",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty='l2')\n",
    "#lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dbfebda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7953024832476084, 0.8705978705978706)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,nb.predict(X_test)),accuracy_score(y_test,nb.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e0d096b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8701227214243595, 0.9146601146601147)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,lr.predict(X_test)),accuracy_score(y_test,lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feebc315",
   "metadata": {},
   "source": [
    "FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f3325c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c05edab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(text,lemmatize = False):\n",
    "    text = to_lower(text)\n",
    "    text = remove_punctuations(text)\n",
    "    tokens = to_tokenize(text)\n",
    "    tokens = remove_stopwords(tokens)\n",
    "    if lemmatize == True:\n",
    "        tokens = lemmatize(tokens)\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2122ac76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20348/20348 [00:06<00:00, 3089.52it/s]\n"
     ]
    }
   ],
   "source": [
    "text = list(df.text)\n",
    "processed_text = []\n",
    "\n",
    "for t in tqdm(text):\n",
    "    processed_text.append(text_processing(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0d85011",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.txt\", \"w\") as file:\n",
    "    file.write(str(processed_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b63eddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  14270\n",
      "Number of labels: 0\n",
      "Progress: 100.0% words/sec/thread:   56410 lr:  0.000000 avg.loss:  1.788019 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.train_unsupervised(\n",
    "    input='data.txt',\n",
    "    model=\"skipgram\",\n",
    "    dim=300,\n",
    "    epoch=10,\n",
    "    lr=0.05,\n",
    "    minn=3,\n",
    "    maxn=6,\n",
    "    minCount=5,\n",
    "    thread=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff21acee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\"fasttext_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1672e907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.8091334104537964, \"'shit\"),\n",
       " (0.7118743062019348, \"shit',\"),\n",
       " (0.709918737411499, 'shite'),\n",
       " (0.549150824546814, \"'hit\"),\n",
       " (0.5461899638175964, 'shine'),\n",
       " (0.5415017008781433, \"'fucking\"),\n",
       " (0.5332852602005005, 'hit'),\n",
       " (0.5323843359947205, \"'hmm\"),\n",
       " (0.530677080154419, 'shift'),\n",
       " (0.5305278301239014, 'shouldnt')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_nearest_neighbors(\"shit\")\n",
    "model.get_word_vector(\"shit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8531bc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier as cbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c9a03ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cbc()\n",
    "fs = fasttext.load_model(\"fasttext_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb611c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs.get_word_vector(processed_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bc399a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#всего 75 слов, нужно получить по каждому слову вектор размерности 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4ebebcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [to_tokenize(doc) for doc in processed_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b446e73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 8422/20348 [00:02<00:03, 3598.25it/s]/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 20348/20348 [00:03<00:00, 5291.91it/s] \n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "for doc in tqdm(temp):\n",
    "    doc_vectors = []\n",
    "    for word in doc:\n",
    "        word_vec = fs.get_word_vector(word)\n",
    "        doc_vectors.append(word_vec)\n",
    "    corpus.append(np.mean(doc_vectors,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "cc619a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_index = []\n",
    "for i in range(len(corpus)):\n",
    "    if np.isnan(corpus[i]).any():\n",
    "        err_index.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3ae9b69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for i in range(len(corpus)):\n",
    "    if i in err_index:\n",
    "        continue\n",
    "    X.append(corpus[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "58d163b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.target.drop(err_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1824e317",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "dc18f680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.032012\n",
      "0:\tlearn: 0.6649399\ttotal: 71.6ms\tremaining: 1m 11s\n",
      "1:\tlearn: 0.6407232\ttotal: 81.9ms\tremaining: 40.8s\n",
      "2:\tlearn: 0.6161068\ttotal: 93ms\tremaining: 30.9s\n",
      "3:\tlearn: 0.5933140\ttotal: 103ms\tremaining: 25.7s\n",
      "4:\tlearn: 0.5707447\ttotal: 113ms\tremaining: 22.6s\n",
      "5:\tlearn: 0.5517391\ttotal: 124ms\tremaining: 20.5s\n",
      "6:\tlearn: 0.5339789\ttotal: 134ms\tremaining: 19.1s\n",
      "7:\tlearn: 0.5189596\ttotal: 145ms\tremaining: 17.9s\n",
      "8:\tlearn: 0.5040701\ttotal: 155ms\tremaining: 17.1s\n",
      "9:\tlearn: 0.4894159\ttotal: 165ms\tremaining: 16.4s\n",
      "10:\tlearn: 0.4760790\ttotal: 176ms\tremaining: 15.8s\n",
      "11:\tlearn: 0.4621985\ttotal: 186ms\tremaining: 15.3s\n",
      "12:\tlearn: 0.4498069\ttotal: 196ms\tremaining: 14.9s\n",
      "13:\tlearn: 0.4398625\ttotal: 206ms\tremaining: 14.5s\n",
      "14:\tlearn: 0.4302468\ttotal: 217ms\tremaining: 14.3s\n",
      "15:\tlearn: 0.4211322\ttotal: 229ms\tremaining: 14.1s\n",
      "16:\tlearn: 0.4122040\ttotal: 240ms\tremaining: 13.9s\n",
      "17:\tlearn: 0.4034320\ttotal: 250ms\tremaining: 13.6s\n",
      "18:\tlearn: 0.3944718\ttotal: 260ms\tremaining: 13.4s\n",
      "19:\tlearn: 0.3870840\ttotal: 270ms\tremaining: 13.3s\n",
      "20:\tlearn: 0.3799532\ttotal: 281ms\tremaining: 13.1s\n",
      "21:\tlearn: 0.3726471\ttotal: 292ms\tremaining: 13s\n",
      "22:\tlearn: 0.3665985\ttotal: 301ms\tremaining: 12.8s\n",
      "23:\tlearn: 0.3601208\ttotal: 311ms\tremaining: 12.7s\n",
      "24:\tlearn: 0.3538219\ttotal: 321ms\tremaining: 12.5s\n",
      "25:\tlearn: 0.3482652\ttotal: 332ms\tremaining: 12.4s\n",
      "26:\tlearn: 0.3428423\ttotal: 342ms\tremaining: 12.3s\n",
      "27:\tlearn: 0.3383113\ttotal: 354ms\tremaining: 12.3s\n",
      "28:\tlearn: 0.3336811\ttotal: 365ms\tremaining: 12.2s\n",
      "29:\tlearn: 0.3294623\ttotal: 375ms\tremaining: 12.1s\n",
      "30:\tlearn: 0.3249180\ttotal: 386ms\tremaining: 12.1s\n",
      "31:\tlearn: 0.3213250\ttotal: 396ms\tremaining: 12s\n",
      "32:\tlearn: 0.3167712\ttotal: 406ms\tremaining: 11.9s\n",
      "33:\tlearn: 0.3129254\ttotal: 417ms\tremaining: 11.8s\n",
      "34:\tlearn: 0.3095447\ttotal: 428ms\tremaining: 11.8s\n",
      "35:\tlearn: 0.3059790\ttotal: 438ms\tremaining: 11.7s\n",
      "36:\tlearn: 0.3028368\ttotal: 448ms\tremaining: 11.6s\n",
      "37:\tlearn: 0.2994998\ttotal: 458ms\tremaining: 11.6s\n",
      "38:\tlearn: 0.2964334\ttotal: 468ms\tremaining: 11.5s\n",
      "39:\tlearn: 0.2931820\ttotal: 477ms\tremaining: 11.5s\n",
      "40:\tlearn: 0.2900101\ttotal: 487ms\tremaining: 11.4s\n",
      "41:\tlearn: 0.2871857\ttotal: 497ms\tremaining: 11.3s\n",
      "42:\tlearn: 0.2842943\ttotal: 507ms\tremaining: 11.3s\n",
      "43:\tlearn: 0.2818274\ttotal: 517ms\tremaining: 11.2s\n",
      "44:\tlearn: 0.2791199\ttotal: 527ms\tremaining: 11.2s\n",
      "45:\tlearn: 0.2767002\ttotal: 537ms\tremaining: 11.1s\n",
      "46:\tlearn: 0.2742395\ttotal: 547ms\tremaining: 11.1s\n",
      "47:\tlearn: 0.2721705\ttotal: 557ms\tremaining: 11s\n",
      "48:\tlearn: 0.2700371\ttotal: 567ms\tremaining: 11s\n",
      "49:\tlearn: 0.2672322\ttotal: 578ms\tremaining: 11s\n",
      "50:\tlearn: 0.2651981\ttotal: 589ms\tremaining: 11s\n",
      "51:\tlearn: 0.2632102\ttotal: 601ms\tremaining: 11s\n",
      "52:\tlearn: 0.2610626\ttotal: 613ms\tremaining: 11s\n",
      "53:\tlearn: 0.2591064\ttotal: 625ms\tremaining: 11s\n",
      "54:\tlearn: 0.2572046\ttotal: 636ms\tremaining: 10.9s\n",
      "55:\tlearn: 0.2554176\ttotal: 647ms\tremaining: 10.9s\n",
      "56:\tlearn: 0.2535558\ttotal: 658ms\tremaining: 10.9s\n",
      "57:\tlearn: 0.2517232\ttotal: 669ms\tremaining: 10.9s\n",
      "58:\tlearn: 0.2500316\ttotal: 679ms\tremaining: 10.8s\n",
      "59:\tlearn: 0.2482545\ttotal: 689ms\tremaining: 10.8s\n",
      "60:\tlearn: 0.2466988\ttotal: 699ms\tremaining: 10.8s\n",
      "61:\tlearn: 0.2450801\ttotal: 709ms\tremaining: 10.7s\n",
      "62:\tlearn: 0.2433480\ttotal: 719ms\tremaining: 10.7s\n",
      "63:\tlearn: 0.2418178\ttotal: 730ms\tremaining: 10.7s\n",
      "64:\tlearn: 0.2403572\ttotal: 740ms\tremaining: 10.6s\n",
      "65:\tlearn: 0.2387581\ttotal: 749ms\tremaining: 10.6s\n",
      "66:\tlearn: 0.2372996\ttotal: 759ms\tremaining: 10.6s\n",
      "67:\tlearn: 0.2359616\ttotal: 769ms\tremaining: 10.5s\n",
      "68:\tlearn: 0.2342847\ttotal: 778ms\tremaining: 10.5s\n",
      "69:\tlearn: 0.2329843\ttotal: 788ms\tremaining: 10.5s\n",
      "70:\tlearn: 0.2315286\ttotal: 798ms\tremaining: 10.4s\n",
      "71:\tlearn: 0.2300744\ttotal: 808ms\tremaining: 10.4s\n",
      "72:\tlearn: 0.2287014\ttotal: 820ms\tremaining: 10.4s\n",
      "73:\tlearn: 0.2273904\ttotal: 830ms\tremaining: 10.4s\n",
      "74:\tlearn: 0.2259319\ttotal: 840ms\tremaining: 10.4s\n",
      "75:\tlearn: 0.2244780\ttotal: 850ms\tremaining: 10.3s\n",
      "76:\tlearn: 0.2232801\ttotal: 859ms\tremaining: 10.3s\n",
      "77:\tlearn: 0.2220577\ttotal: 869ms\tremaining: 10.3s\n",
      "78:\tlearn: 0.2209930\ttotal: 878ms\tremaining: 10.2s\n",
      "79:\tlearn: 0.2197676\ttotal: 888ms\tremaining: 10.2s\n",
      "80:\tlearn: 0.2186671\ttotal: 898ms\tremaining: 10.2s\n",
      "81:\tlearn: 0.2176599\ttotal: 908ms\tremaining: 10.2s\n",
      "82:\tlearn: 0.2165365\ttotal: 918ms\tremaining: 10.1s\n",
      "83:\tlearn: 0.2155435\ttotal: 928ms\tremaining: 10.1s\n",
      "84:\tlearn: 0.2144486\ttotal: 938ms\tremaining: 10.1s\n",
      "85:\tlearn: 0.2134284\ttotal: 948ms\tremaining: 10.1s\n",
      "86:\tlearn: 0.2124591\ttotal: 958ms\tremaining: 10s\n",
      "87:\tlearn: 0.2114366\ttotal: 967ms\tremaining: 10s\n",
      "88:\tlearn: 0.2105030\ttotal: 977ms\tremaining: 10s\n",
      "89:\tlearn: 0.2097000\ttotal: 986ms\tremaining: 9.97s\n",
      "90:\tlearn: 0.2085673\ttotal: 996ms\tremaining: 9.95s\n",
      "91:\tlearn: 0.2076974\ttotal: 1s\tremaining: 9.92s\n",
      "92:\tlearn: 0.2067915\ttotal: 1.01s\tremaining: 9.91s\n",
      "93:\tlearn: 0.2057291\ttotal: 1.03s\tremaining: 9.9s\n",
      "94:\tlearn: 0.2047092\ttotal: 1.04s\tremaining: 9.89s\n",
      "95:\tlearn: 0.2038035\ttotal: 1.05s\tremaining: 9.87s\n",
      "96:\tlearn: 0.2028369\ttotal: 1.06s\tremaining: 9.85s\n",
      "97:\tlearn: 0.2017505\ttotal: 1.07s\tremaining: 9.83s\n",
      "98:\tlearn: 0.2010807\ttotal: 1.08s\tremaining: 9.8s\n",
      "99:\tlearn: 0.2002873\ttotal: 1.09s\tremaining: 9.79s\n",
      "100:\tlearn: 0.1995038\ttotal: 1.1s\tremaining: 9.8s\n",
      "101:\tlearn: 0.1987078\ttotal: 1.11s\tremaining: 9.81s\n",
      "102:\tlearn: 0.1978491\ttotal: 1.13s\tremaining: 9.8s\n",
      "103:\tlearn: 0.1969475\ttotal: 1.14s\tremaining: 9.79s\n",
      "104:\tlearn: 0.1961260\ttotal: 1.15s\tremaining: 9.79s\n",
      "105:\tlearn: 0.1951853\ttotal: 1.16s\tremaining: 9.77s\n",
      "106:\tlearn: 0.1944477\ttotal: 1.17s\tremaining: 9.75s\n",
      "107:\tlearn: 0.1938023\ttotal: 1.18s\tremaining: 9.73s\n",
      "108:\tlearn: 0.1929362\ttotal: 1.19s\tremaining: 9.71s\n",
      "109:\tlearn: 0.1922498\ttotal: 1.2s\tremaining: 9.69s\n",
      "110:\tlearn: 0.1916501\ttotal: 1.21s\tremaining: 9.66s\n",
      "111:\tlearn: 0.1909597\ttotal: 1.22s\tremaining: 9.64s\n",
      "112:\tlearn: 0.1903193\ttotal: 1.23s\tremaining: 9.63s\n",
      "113:\tlearn: 0.1896248\ttotal: 1.24s\tremaining: 9.62s\n",
      "114:\tlearn: 0.1889264\ttotal: 1.25s\tremaining: 9.6s\n",
      "115:\tlearn: 0.1882251\ttotal: 1.26s\tremaining: 9.58s\n",
      "116:\tlearn: 0.1875401\ttotal: 1.27s\tremaining: 9.57s\n",
      "117:\tlearn: 0.1869139\ttotal: 1.28s\tremaining: 9.54s\n",
      "118:\tlearn: 0.1861990\ttotal: 1.29s\tremaining: 9.53s\n",
      "119:\tlearn: 0.1855238\ttotal: 1.3s\tremaining: 9.51s\n",
      "120:\tlearn: 0.1848615\ttotal: 1.31s\tremaining: 9.49s\n",
      "121:\tlearn: 0.1841816\ttotal: 1.31s\tremaining: 9.47s\n",
      "122:\tlearn: 0.1835438\ttotal: 1.32s\tremaining: 9.45s\n",
      "123:\tlearn: 0.1829312\ttotal: 1.33s\tremaining: 9.43s\n",
      "124:\tlearn: 0.1821750\ttotal: 1.34s\tremaining: 9.41s\n",
      "125:\tlearn: 0.1814459\ttotal: 1.35s\tremaining: 9.39s\n",
      "126:\tlearn: 0.1809283\ttotal: 1.36s\tremaining: 9.38s\n",
      "127:\tlearn: 0.1801936\ttotal: 1.37s\tremaining: 9.36s\n",
      "128:\tlearn: 0.1795751\ttotal: 1.38s\tremaining: 9.35s\n",
      "129:\tlearn: 0.1788730\ttotal: 1.39s\tremaining: 9.33s\n",
      "130:\tlearn: 0.1782157\ttotal: 1.4s\tremaining: 9.32s\n",
      "131:\tlearn: 0.1776908\ttotal: 1.41s\tremaining: 9.3s\n",
      "132:\tlearn: 0.1770804\ttotal: 1.42s\tremaining: 9.28s\n",
      "133:\tlearn: 0.1764590\ttotal: 1.44s\tremaining: 9.27s\n",
      "134:\tlearn: 0.1758227\ttotal: 1.45s\tremaining: 9.26s\n",
      "135:\tlearn: 0.1752022\ttotal: 1.45s\tremaining: 9.24s\n",
      "136:\tlearn: 0.1746656\ttotal: 1.46s\tremaining: 9.22s\n",
      "137:\tlearn: 0.1741485\ttotal: 1.47s\tremaining: 9.2s\n",
      "138:\tlearn: 0.1735665\ttotal: 1.48s\tremaining: 9.19s\n",
      "139:\tlearn: 0.1730523\ttotal: 1.49s\tremaining: 9.17s\n",
      "140:\tlearn: 0.1724750\ttotal: 1.5s\tremaining: 9.15s\n",
      "141:\tlearn: 0.1718888\ttotal: 1.51s\tremaining: 9.14s\n",
      "142:\tlearn: 0.1713428\ttotal: 1.52s\tremaining: 9.12s\n",
      "143:\tlearn: 0.1707909\ttotal: 1.53s\tremaining: 9.11s\n",
      "144:\tlearn: 0.1702963\ttotal: 1.54s\tremaining: 9.09s\n",
      "145:\tlearn: 0.1698161\ttotal: 1.55s\tremaining: 9.08s\n",
      "146:\tlearn: 0.1692695\ttotal: 1.56s\tremaining: 9.06s\n",
      "147:\tlearn: 0.1687535\ttotal: 1.57s\tremaining: 9.05s\n",
      "148:\tlearn: 0.1681703\ttotal: 1.58s\tremaining: 9.03s\n",
      "149:\tlearn: 0.1677169\ttotal: 1.59s\tremaining: 9.02s\n",
      "150:\tlearn: 0.1672504\ttotal: 1.6s\tremaining: 9s\n",
      "151:\tlearn: 0.1667499\ttotal: 1.61s\tremaining: 8.99s\n",
      "152:\tlearn: 0.1663235\ttotal: 1.62s\tremaining: 8.97s\n",
      "153:\tlearn: 0.1659020\ttotal: 1.63s\tremaining: 8.96s\n",
      "154:\tlearn: 0.1654799\ttotal: 1.64s\tremaining: 8.95s\n",
      "155:\tlearn: 0.1650493\ttotal: 1.65s\tremaining: 8.94s\n",
      "156:\tlearn: 0.1645128\ttotal: 1.66s\tremaining: 8.92s\n",
      "157:\tlearn: 0.1640539\ttotal: 1.67s\tremaining: 8.9s\n",
      "158:\tlearn: 0.1635276\ttotal: 1.68s\tremaining: 8.89s\n",
      "159:\tlearn: 0.1630634\ttotal: 1.69s\tremaining: 8.88s\n",
      "160:\tlearn: 0.1625267\ttotal: 1.7s\tremaining: 8.86s\n",
      "161:\tlearn: 0.1620423\ttotal: 1.71s\tremaining: 8.85s\n",
      "162:\tlearn: 0.1615242\ttotal: 1.72s\tremaining: 8.83s\n",
      "163:\tlearn: 0.1610755\ttotal: 1.73s\tremaining: 8.82s\n",
      "164:\tlearn: 0.1607414\ttotal: 1.74s\tremaining: 8.8s\n",
      "165:\tlearn: 0.1603129\ttotal: 1.75s\tremaining: 8.79s\n",
      "166:\tlearn: 0.1599482\ttotal: 1.76s\tremaining: 8.77s\n",
      "167:\tlearn: 0.1594998\ttotal: 1.77s\tremaining: 8.76s\n",
      "168:\tlearn: 0.1589903\ttotal: 1.78s\tremaining: 8.75s\n",
      "169:\tlearn: 0.1586451\ttotal: 1.79s\tremaining: 8.74s\n",
      "170:\tlearn: 0.1582449\ttotal: 1.8s\tremaining: 8.73s\n",
      "171:\tlearn: 0.1579307\ttotal: 1.81s\tremaining: 8.72s\n",
      "172:\tlearn: 0.1575573\ttotal: 1.82s\tremaining: 8.7s\n",
      "173:\tlearn: 0.1570662\ttotal: 1.83s\tremaining: 8.7s\n",
      "174:\tlearn: 0.1565926\ttotal: 1.84s\tremaining: 8.68s\n",
      "175:\tlearn: 0.1561299\ttotal: 1.85s\tremaining: 8.68s\n",
      "176:\tlearn: 0.1556962\ttotal: 1.86s\tremaining: 8.66s\n",
      "177:\tlearn: 0.1552346\ttotal: 1.87s\tremaining: 8.65s\n",
      "178:\tlearn: 0.1548368\ttotal: 1.88s\tremaining: 8.64s\n",
      "179:\tlearn: 0.1544866\ttotal: 1.89s\tremaining: 8.63s\n",
      "180:\tlearn: 0.1539939\ttotal: 1.9s\tremaining: 8.61s\n",
      "181:\tlearn: 0.1536609\ttotal: 1.91s\tremaining: 8.6s\n",
      "182:\tlearn: 0.1531742\ttotal: 1.92s\tremaining: 8.58s\n",
      "183:\tlearn: 0.1527200\ttotal: 1.93s\tremaining: 8.57s\n",
      "184:\tlearn: 0.1523566\ttotal: 1.94s\tremaining: 8.56s\n",
      "185:\tlearn: 0.1519483\ttotal: 1.95s\tremaining: 8.55s\n",
      "186:\tlearn: 0.1515243\ttotal: 1.96s\tremaining: 8.54s\n",
      "187:\tlearn: 0.1511611\ttotal: 1.97s\tremaining: 8.52s\n",
      "188:\tlearn: 0.1507206\ttotal: 1.98s\tremaining: 8.51s\n",
      "189:\tlearn: 0.1504249\ttotal: 1.99s\tremaining: 8.49s\n",
      "190:\tlearn: 0.1500967\ttotal: 2s\tremaining: 8.48s\n",
      "191:\tlearn: 0.1497369\ttotal: 2.01s\tremaining: 8.46s\n",
      "192:\tlearn: 0.1493221\ttotal: 2.02s\tremaining: 8.45s\n",
      "193:\tlearn: 0.1490761\ttotal: 2.03s\tremaining: 8.44s\n",
      "194:\tlearn: 0.1487587\ttotal: 2.04s\tremaining: 8.42s\n",
      "195:\tlearn: 0.1483203\ttotal: 2.05s\tremaining: 8.41s\n",
      "196:\tlearn: 0.1478758\ttotal: 2.06s\tremaining: 8.4s\n",
      "197:\tlearn: 0.1475117\ttotal: 2.07s\tremaining: 8.39s\n",
      "198:\tlearn: 0.1472207\ttotal: 2.08s\tremaining: 8.38s\n",
      "199:\tlearn: 0.1468587\ttotal: 2.09s\tremaining: 8.37s\n",
      "200:\tlearn: 0.1465500\ttotal: 2.1s\tremaining: 8.35s\n",
      "201:\tlearn: 0.1461773\ttotal: 2.11s\tremaining: 8.34s\n",
      "202:\tlearn: 0.1458586\ttotal: 2.12s\tremaining: 8.32s\n",
      "203:\tlearn: 0.1453955\ttotal: 2.13s\tremaining: 8.31s\n",
      "204:\tlearn: 0.1451005\ttotal: 2.14s\tremaining: 8.3s\n",
      "205:\tlearn: 0.1447416\ttotal: 2.15s\tremaining: 8.29s\n",
      "206:\tlearn: 0.1443012\ttotal: 2.16s\tremaining: 8.27s\n",
      "207:\tlearn: 0.1440471\ttotal: 2.17s\tremaining: 8.26s\n",
      "208:\tlearn: 0.1437189\ttotal: 2.18s\tremaining: 8.25s\n",
      "209:\tlearn: 0.1434239\ttotal: 2.19s\tremaining: 8.23s\n",
      "210:\tlearn: 0.1431545\ttotal: 2.2s\tremaining: 8.22s\n",
      "211:\tlearn: 0.1428525\ttotal: 2.21s\tremaining: 8.21s\n",
      "212:\tlearn: 0.1425686\ttotal: 2.22s\tremaining: 8.19s\n",
      "213:\tlearn: 0.1422693\ttotal: 2.23s\tremaining: 8.18s\n",
      "214:\tlearn: 0.1419114\ttotal: 2.24s\tremaining: 8.17s\n",
      "215:\tlearn: 0.1414590\ttotal: 2.25s\tremaining: 8.16s\n",
      "216:\tlearn: 0.1411868\ttotal: 2.26s\tremaining: 8.15s\n",
      "217:\tlearn: 0.1409208\ttotal: 2.27s\tremaining: 8.14s\n",
      "218:\tlearn: 0.1406540\ttotal: 2.28s\tremaining: 8.12s\n",
      "219:\tlearn: 0.1402920\ttotal: 2.29s\tremaining: 8.11s\n",
      "220:\tlearn: 0.1397590\ttotal: 2.3s\tremaining: 8.1s\n",
      "221:\tlearn: 0.1394080\ttotal: 2.31s\tremaining: 8.09s\n",
      "222:\tlearn: 0.1390317\ttotal: 2.32s\tremaining: 8.07s\n",
      "223:\tlearn: 0.1387424\ttotal: 2.33s\tremaining: 8.06s\n",
      "224:\tlearn: 0.1384541\ttotal: 2.34s\tremaining: 8.05s\n",
      "225:\tlearn: 0.1381018\ttotal: 2.35s\tremaining: 8.04s\n",
      "226:\tlearn: 0.1377421\ttotal: 2.36s\tremaining: 8.03s\n",
      "227:\tlearn: 0.1374657\ttotal: 2.37s\tremaining: 8.01s\n",
      "228:\tlearn: 0.1371416\ttotal: 2.38s\tremaining: 8s\n",
      "229:\tlearn: 0.1368181\ttotal: 2.38s\tremaining: 7.99s\n",
      "230:\tlearn: 0.1365025\ttotal: 2.4s\tremaining: 7.97s\n",
      "231:\tlearn: 0.1361583\ttotal: 2.4s\tremaining: 7.96s\n",
      "232:\tlearn: 0.1358823\ttotal: 2.41s\tremaining: 7.95s\n",
      "233:\tlearn: 0.1355477\ttotal: 2.42s\tremaining: 7.94s\n",
      "234:\tlearn: 0.1353151\ttotal: 2.43s\tremaining: 7.92s\n",
      "235:\tlearn: 0.1349976\ttotal: 2.44s\tremaining: 7.91s\n",
      "236:\tlearn: 0.1347319\ttotal: 2.45s\tremaining: 7.9s\n",
      "237:\tlearn: 0.1344223\ttotal: 2.46s\tremaining: 7.89s\n",
      "238:\tlearn: 0.1341329\ttotal: 2.47s\tremaining: 7.88s\n",
      "239:\tlearn: 0.1337849\ttotal: 2.48s\tremaining: 7.87s\n",
      "240:\tlearn: 0.1335395\ttotal: 2.49s\tremaining: 7.85s\n",
      "241:\tlearn: 0.1332348\ttotal: 2.5s\tremaining: 7.84s\n",
      "242:\tlearn: 0.1330082\ttotal: 2.51s\tremaining: 7.83s\n",
      "243:\tlearn: 0.1327565\ttotal: 2.52s\tremaining: 7.81s\n",
      "244:\tlearn: 0.1324117\ttotal: 2.53s\tremaining: 7.8s\n",
      "245:\tlearn: 0.1321518\ttotal: 2.59s\tremaining: 7.95s\n",
      "246:\tlearn: 0.1318645\ttotal: 2.61s\tremaining: 7.95s\n",
      "247:\tlearn: 0.1315844\ttotal: 2.62s\tremaining: 7.94s\n",
      "248:\tlearn: 0.1313171\ttotal: 2.63s\tremaining: 7.93s\n",
      "249:\tlearn: 0.1309920\ttotal: 2.64s\tremaining: 7.91s\n",
      "250:\tlearn: 0.1305725\ttotal: 2.65s\tremaining: 7.91s\n",
      "251:\tlearn: 0.1302842\ttotal: 2.66s\tremaining: 7.91s\n",
      "252:\tlearn: 0.1299239\ttotal: 2.68s\tremaining: 7.92s\n",
      "253:\tlearn: 0.1296633\ttotal: 2.69s\tremaining: 7.91s\n",
      "254:\tlearn: 0.1294187\ttotal: 2.7s\tremaining: 7.9s\n",
      "255:\tlearn: 0.1291717\ttotal: 2.72s\tremaining: 7.89s\n",
      "256:\tlearn: 0.1289381\ttotal: 2.73s\tremaining: 7.88s\n",
      "257:\tlearn: 0.1287398\ttotal: 2.74s\tremaining: 7.87s\n",
      "258:\tlearn: 0.1285182\ttotal: 2.75s\tremaining: 7.86s\n",
      "259:\tlearn: 0.1282435\ttotal: 2.76s\tremaining: 7.85s\n",
      "260:\tlearn: 0.1279319\ttotal: 2.77s\tremaining: 7.84s\n",
      "261:\tlearn: 0.1276842\ttotal: 2.78s\tremaining: 7.82s\n",
      "262:\tlearn: 0.1274198\ttotal: 2.79s\tremaining: 7.81s\n",
      "263:\tlearn: 0.1271174\ttotal: 2.8s\tremaining: 7.8s\n",
      "264:\tlearn: 0.1268116\ttotal: 2.81s\tremaining: 7.78s\n",
      "265:\tlearn: 0.1265531\ttotal: 2.82s\tremaining: 7.77s\n",
      "266:\tlearn: 0.1262095\ttotal: 2.83s\tremaining: 7.76s\n",
      "267:\tlearn: 0.1258494\ttotal: 2.83s\tremaining: 7.75s\n",
      "268:\tlearn: 0.1255791\ttotal: 2.85s\tremaining: 7.73s\n",
      "269:\tlearn: 0.1252886\ttotal: 2.86s\tremaining: 7.72s\n",
      "270:\tlearn: 0.1250539\ttotal: 2.87s\tremaining: 7.71s\n",
      "271:\tlearn: 0.1247881\ttotal: 2.88s\tremaining: 7.7s\n",
      "272:\tlearn: 0.1245841\ttotal: 2.89s\tremaining: 7.69s\n",
      "273:\tlearn: 0.1242208\ttotal: 2.9s\tremaining: 7.68s\n",
      "274:\tlearn: 0.1239203\ttotal: 2.91s\tremaining: 7.67s\n",
      "275:\tlearn: 0.1236357\ttotal: 2.92s\tremaining: 7.66s\n",
      "276:\tlearn: 0.1233962\ttotal: 2.93s\tremaining: 7.65s\n",
      "277:\tlearn: 0.1230951\ttotal: 2.94s\tremaining: 7.65s\n",
      "278:\tlearn: 0.1228241\ttotal: 2.96s\tremaining: 7.64s\n",
      "279:\tlearn: 0.1225795\ttotal: 2.97s\tremaining: 7.63s\n",
      "280:\tlearn: 0.1222868\ttotal: 2.98s\tremaining: 7.62s\n",
      "281:\tlearn: 0.1219561\ttotal: 2.99s\tremaining: 7.61s\n",
      "282:\tlearn: 0.1216026\ttotal: 3s\tremaining: 7.6s\n",
      "283:\tlearn: 0.1213855\ttotal: 3.01s\tremaining: 7.59s\n",
      "284:\tlearn: 0.1210934\ttotal: 3.02s\tremaining: 7.57s\n",
      "285:\tlearn: 0.1208545\ttotal: 3.03s\tremaining: 7.56s\n",
      "286:\tlearn: 0.1205913\ttotal: 3.04s\tremaining: 7.55s\n",
      "287:\tlearn: 0.1203191\ttotal: 3.05s\tremaining: 7.54s\n",
      "288:\tlearn: 0.1200110\ttotal: 3.06s\tremaining: 7.53s\n",
      "289:\tlearn: 0.1197717\ttotal: 3.07s\tremaining: 7.52s\n",
      "290:\tlearn: 0.1195010\ttotal: 3.08s\tremaining: 7.51s\n",
      "291:\tlearn: 0.1192844\ttotal: 3.09s\tremaining: 7.5s\n",
      "292:\tlearn: 0.1190300\ttotal: 3.1s\tremaining: 7.49s\n",
      "293:\tlearn: 0.1187261\ttotal: 3.11s\tremaining: 7.47s\n",
      "294:\tlearn: 0.1185132\ttotal: 3.12s\tremaining: 7.46s\n",
      "295:\tlearn: 0.1182525\ttotal: 3.13s\tremaining: 7.45s\n",
      "296:\tlearn: 0.1179536\ttotal: 3.14s\tremaining: 7.44s\n",
      "297:\tlearn: 0.1177265\ttotal: 3.15s\tremaining: 7.43s\n",
      "298:\tlearn: 0.1174094\ttotal: 3.16s\tremaining: 7.42s\n",
      "299:\tlearn: 0.1171072\ttotal: 3.17s\tremaining: 7.4s\n",
      "300:\tlearn: 0.1168121\ttotal: 3.18s\tremaining: 7.39s\n",
      "301:\tlearn: 0.1166000\ttotal: 3.19s\tremaining: 7.38s\n",
      "302:\tlearn: 0.1163210\ttotal: 3.2s\tremaining: 7.37s\n",
      "303:\tlearn: 0.1160886\ttotal: 3.21s\tremaining: 7.35s\n",
      "304:\tlearn: 0.1158427\ttotal: 3.22s\tremaining: 7.34s\n",
      "305:\tlearn: 0.1155336\ttotal: 3.23s\tremaining: 7.33s\n",
      "306:\tlearn: 0.1152376\ttotal: 3.24s\tremaining: 7.32s\n",
      "307:\tlearn: 0.1150227\ttotal: 3.25s\tremaining: 7.3s\n",
      "308:\tlearn: 0.1148241\ttotal: 3.26s\tremaining: 7.29s\n",
      "309:\tlearn: 0.1145172\ttotal: 3.27s\tremaining: 7.28s\n",
      "310:\tlearn: 0.1141852\ttotal: 3.28s\tremaining: 7.27s\n",
      "311:\tlearn: 0.1139959\ttotal: 3.29s\tremaining: 7.26s\n",
      "312:\tlearn: 0.1137769\ttotal: 3.3s\tremaining: 7.24s\n",
      "313:\tlearn: 0.1134997\ttotal: 3.31s\tremaining: 7.23s\n",
      "314:\tlearn: 0.1132202\ttotal: 3.32s\tremaining: 7.22s\n",
      "315:\tlearn: 0.1129193\ttotal: 3.33s\tremaining: 7.21s\n",
      "316:\tlearn: 0.1126743\ttotal: 3.34s\tremaining: 7.2s\n",
      "317:\tlearn: 0.1123891\ttotal: 3.35s\tremaining: 7.18s\n",
      "318:\tlearn: 0.1120894\ttotal: 3.36s\tremaining: 7.17s\n",
      "319:\tlearn: 0.1117587\ttotal: 3.37s\tremaining: 7.16s\n",
      "320:\tlearn: 0.1114921\ttotal: 3.38s\tremaining: 7.15s\n",
      "321:\tlearn: 0.1112380\ttotal: 3.39s\tremaining: 7.13s\n",
      "322:\tlearn: 0.1109793\ttotal: 3.4s\tremaining: 7.12s\n",
      "323:\tlearn: 0.1106658\ttotal: 3.41s\tremaining: 7.11s\n",
      "324:\tlearn: 0.1103834\ttotal: 3.42s\tremaining: 7.1s\n",
      "325:\tlearn: 0.1101205\ttotal: 3.43s\tremaining: 7.08s\n",
      "326:\tlearn: 0.1097974\ttotal: 3.44s\tremaining: 7.07s\n",
      "327:\tlearn: 0.1095478\ttotal: 3.45s\tremaining: 7.06s\n",
      "328:\tlearn: 0.1093335\ttotal: 3.46s\tremaining: 7.05s\n",
      "329:\tlearn: 0.1090414\ttotal: 3.47s\tremaining: 7.04s\n",
      "330:\tlearn: 0.1088361\ttotal: 3.48s\tremaining: 7.03s\n",
      "331:\tlearn: 0.1086562\ttotal: 3.49s\tremaining: 7.01s\n",
      "332:\tlearn: 0.1084488\ttotal: 3.5s\tremaining: 7s\n",
      "333:\tlearn: 0.1082259\ttotal: 3.51s\tremaining: 6.99s\n",
      "334:\tlearn: 0.1079908\ttotal: 3.52s\tremaining: 6.98s\n",
      "335:\tlearn: 0.1077731\ttotal: 3.52s\tremaining: 6.97s\n",
      "336:\tlearn: 0.1074938\ttotal: 3.54s\tremaining: 6.96s\n",
      "337:\tlearn: 0.1071807\ttotal: 3.54s\tremaining: 6.94s\n",
      "338:\tlearn: 0.1068968\ttotal: 3.56s\tremaining: 6.93s\n",
      "339:\tlearn: 0.1066029\ttotal: 3.56s\tremaining: 6.92s\n",
      "340:\tlearn: 0.1063467\ttotal: 3.58s\tremaining: 6.91s\n",
      "341:\tlearn: 0.1060710\ttotal: 3.58s\tremaining: 6.9s\n",
      "342:\tlearn: 0.1057917\ttotal: 3.6s\tremaining: 6.89s\n",
      "343:\tlearn: 0.1055805\ttotal: 3.6s\tremaining: 6.88s\n",
      "344:\tlearn: 0.1053293\ttotal: 3.61s\tremaining: 6.86s\n",
      "345:\tlearn: 0.1051262\ttotal: 3.62s\tremaining: 6.85s\n",
      "346:\tlearn: 0.1048081\ttotal: 3.63s\tremaining: 6.84s\n",
      "347:\tlearn: 0.1045468\ttotal: 3.64s\tremaining: 6.83s\n",
      "348:\tlearn: 0.1041721\ttotal: 3.65s\tremaining: 6.82s\n",
      "349:\tlearn: 0.1039354\ttotal: 3.67s\tremaining: 6.81s\n",
      "350:\tlearn: 0.1037398\ttotal: 3.67s\tremaining: 6.79s\n",
      "351:\tlearn: 0.1034521\ttotal: 3.69s\tremaining: 6.78s\n",
      "352:\tlearn: 0.1031689\ttotal: 3.69s\tremaining: 6.77s\n",
      "353:\tlearn: 0.1028898\ttotal: 3.71s\tremaining: 6.76s\n",
      "354:\tlearn: 0.1026115\ttotal: 3.71s\tremaining: 6.75s\n",
      "355:\tlearn: 0.1023509\ttotal: 3.73s\tremaining: 6.74s\n",
      "356:\tlearn: 0.1021274\ttotal: 3.73s\tremaining: 6.73s\n",
      "357:\tlearn: 0.1018507\ttotal: 3.75s\tremaining: 6.72s\n",
      "358:\tlearn: 0.1016347\ttotal: 3.75s\tremaining: 6.71s\n",
      "359:\tlearn: 0.1014212\ttotal: 3.77s\tremaining: 6.7s\n",
      "360:\tlearn: 0.1012270\ttotal: 3.78s\tremaining: 6.68s\n",
      "361:\tlearn: 0.1009374\ttotal: 3.79s\tremaining: 6.67s\n",
      "362:\tlearn: 0.1006941\ttotal: 3.79s\tremaining: 6.66s\n",
      "363:\tlearn: 0.1004796\ttotal: 3.81s\tremaining: 6.65s\n",
      "364:\tlearn: 0.1002041\ttotal: 3.81s\tremaining: 6.64s\n",
      "365:\tlearn: 0.0999718\ttotal: 3.82s\tremaining: 6.62s\n",
      "366:\tlearn: 0.0997753\ttotal: 3.83s\tremaining: 6.61s\n",
      "367:\tlearn: 0.0994812\ttotal: 3.84s\tremaining: 6.6s\n",
      "368:\tlearn: 0.0993073\ttotal: 3.85s\tremaining: 6.59s\n",
      "369:\tlearn: 0.0990624\ttotal: 3.86s\tremaining: 6.58s\n",
      "370:\tlearn: 0.0988482\ttotal: 3.87s\tremaining: 6.57s\n",
      "371:\tlearn: 0.0985848\ttotal: 3.88s\tremaining: 6.56s\n",
      "372:\tlearn: 0.0983344\ttotal: 3.89s\tremaining: 6.54s\n",
      "373:\tlearn: 0.0981423\ttotal: 3.9s\tremaining: 6.53s\n",
      "374:\tlearn: 0.0978748\ttotal: 3.92s\tremaining: 6.53s\n",
      "375:\tlearn: 0.0975997\ttotal: 3.93s\tremaining: 6.51s\n",
      "376:\tlearn: 0.0973304\ttotal: 3.94s\tremaining: 6.5s\n",
      "377:\tlearn: 0.0971070\ttotal: 3.95s\tremaining: 6.49s\n",
      "378:\tlearn: 0.0968687\ttotal: 3.96s\tremaining: 6.48s\n",
      "379:\tlearn: 0.0966001\ttotal: 3.97s\tremaining: 6.47s\n",
      "380:\tlearn: 0.0963736\ttotal: 3.98s\tremaining: 6.46s\n",
      "381:\tlearn: 0.0962057\ttotal: 3.98s\tremaining: 6.45s\n",
      "382:\tlearn: 0.0959327\ttotal: 4s\tremaining: 6.44s\n",
      "383:\tlearn: 0.0956285\ttotal: 4s\tremaining: 6.42s\n",
      "384:\tlearn: 0.0953549\ttotal: 4.01s\tremaining: 6.41s\n",
      "385:\tlearn: 0.0951505\ttotal: 4.03s\tremaining: 6.4s\n",
      "386:\tlearn: 0.0948432\ttotal: 4.04s\tremaining: 6.39s\n",
      "387:\tlearn: 0.0946047\ttotal: 4.04s\tremaining: 6.38s\n",
      "388:\tlearn: 0.0944592\ttotal: 4.05s\tremaining: 6.37s\n",
      "389:\tlearn: 0.0941993\ttotal: 4.07s\tremaining: 6.36s\n",
      "390:\tlearn: 0.0939911\ttotal: 4.08s\tremaining: 6.35s\n",
      "391:\tlearn: 0.0937737\ttotal: 4.08s\tremaining: 6.34s\n",
      "392:\tlearn: 0.0935453\ttotal: 4.09s\tremaining: 6.32s\n",
      "393:\tlearn: 0.0933489\ttotal: 4.1s\tremaining: 6.31s\n",
      "394:\tlearn: 0.0931070\ttotal: 4.12s\tremaining: 6.3s\n",
      "395:\tlearn: 0.0928770\ttotal: 4.13s\tremaining: 6.29s\n",
      "396:\tlearn: 0.0926106\ttotal: 4.14s\tremaining: 6.28s\n",
      "397:\tlearn: 0.0923831\ttotal: 4.15s\tremaining: 6.27s\n",
      "398:\tlearn: 0.0921518\ttotal: 4.16s\tremaining: 6.26s\n",
      "399:\tlearn: 0.0919266\ttotal: 4.17s\tremaining: 6.25s\n",
      "400:\tlearn: 0.0916652\ttotal: 4.18s\tremaining: 6.24s\n",
      "401:\tlearn: 0.0914478\ttotal: 4.19s\tremaining: 6.23s\n",
      "402:\tlearn: 0.0912886\ttotal: 4.2s\tremaining: 6.22s\n",
      "403:\tlearn: 0.0911008\ttotal: 4.21s\tremaining: 6.21s\n",
      "404:\tlearn: 0.0908561\ttotal: 4.22s\tremaining: 6.19s\n",
      "405:\tlearn: 0.0906444\ttotal: 4.23s\tremaining: 6.18s\n",
      "406:\tlearn: 0.0904018\ttotal: 4.24s\tremaining: 6.17s\n",
      "407:\tlearn: 0.0901821\ttotal: 4.25s\tremaining: 6.16s\n",
      "408:\tlearn: 0.0899772\ttotal: 4.26s\tremaining: 6.15s\n",
      "409:\tlearn: 0.0897568\ttotal: 4.27s\tremaining: 6.14s\n",
      "410:\tlearn: 0.0895840\ttotal: 4.28s\tremaining: 6.13s\n",
      "411:\tlearn: 0.0893163\ttotal: 4.29s\tremaining: 6.12s\n",
      "412:\tlearn: 0.0890799\ttotal: 4.3s\tremaining: 6.11s\n",
      "413:\tlearn: 0.0888768\ttotal: 4.31s\tremaining: 6.1s\n",
      "414:\tlearn: 0.0887161\ttotal: 4.32s\tremaining: 6.08s\n",
      "415:\tlearn: 0.0885494\ttotal: 4.33s\tremaining: 6.07s\n",
      "416:\tlearn: 0.0883493\ttotal: 4.34s\tremaining: 6.06s\n",
      "417:\tlearn: 0.0882257\ttotal: 4.35s\tremaining: 6.05s\n",
      "418:\tlearn: 0.0880066\ttotal: 4.36s\tremaining: 6.04s\n",
      "419:\tlearn: 0.0877256\ttotal: 4.37s\tremaining: 6.03s\n",
      "420:\tlearn: 0.0875820\ttotal: 4.38s\tremaining: 6.02s\n",
      "421:\tlearn: 0.0873787\ttotal: 4.39s\tremaining: 6.01s\n",
      "422:\tlearn: 0.0871848\ttotal: 4.4s\tremaining: 6s\n",
      "423:\tlearn: 0.0869743\ttotal: 4.41s\tremaining: 5.99s\n",
      "424:\tlearn: 0.0868521\ttotal: 4.42s\tremaining: 5.97s\n",
      "425:\tlearn: 0.0866530\ttotal: 4.42s\tremaining: 5.96s\n",
      "426:\tlearn: 0.0864189\ttotal: 4.43s\tremaining: 5.95s\n",
      "427:\tlearn: 0.0861713\ttotal: 4.45s\tremaining: 5.94s\n",
      "428:\tlearn: 0.0859736\ttotal: 4.46s\tremaining: 5.93s\n",
      "429:\tlearn: 0.0857137\ttotal: 4.46s\tremaining: 5.92s\n",
      "430:\tlearn: 0.0854968\ttotal: 4.47s\tremaining: 5.91s\n",
      "431:\tlearn: 0.0853017\ttotal: 4.49s\tremaining: 5.9s\n",
      "432:\tlearn: 0.0852155\ttotal: 4.5s\tremaining: 5.89s\n",
      "433:\tlearn: 0.0850202\ttotal: 4.5s\tremaining: 5.88s\n",
      "434:\tlearn: 0.0848459\ttotal: 4.51s\tremaining: 5.86s\n",
      "435:\tlearn: 0.0846883\ttotal: 4.53s\tremaining: 5.86s\n",
      "436:\tlearn: 0.0844771\ttotal: 4.58s\tremaining: 5.89s\n",
      "437:\tlearn: 0.0843475\ttotal: 4.59s\tremaining: 5.89s\n",
      "438:\tlearn: 0.0841516\ttotal: 4.6s\tremaining: 5.88s\n",
      "439:\tlearn: 0.0839327\ttotal: 4.61s\tremaining: 5.87s\n",
      "440:\tlearn: 0.0836891\ttotal: 4.62s\tremaining: 5.86s\n",
      "441:\tlearn: 0.0834584\ttotal: 4.63s\tremaining: 5.84s\n",
      "442:\tlearn: 0.0832642\ttotal: 4.64s\tremaining: 5.83s\n",
      "443:\tlearn: 0.0830828\ttotal: 4.65s\tremaining: 5.82s\n",
      "444:\tlearn: 0.0828861\ttotal: 4.66s\tremaining: 5.81s\n",
      "445:\tlearn: 0.0826752\ttotal: 4.67s\tremaining: 5.8s\n",
      "446:\tlearn: 0.0825294\ttotal: 4.68s\tremaining: 5.79s\n",
      "447:\tlearn: 0.0823486\ttotal: 4.69s\tremaining: 5.78s\n",
      "448:\tlearn: 0.0821319\ttotal: 4.7s\tremaining: 5.76s\n",
      "449:\tlearn: 0.0819361\ttotal: 4.71s\tremaining: 5.75s\n",
      "450:\tlearn: 0.0817831\ttotal: 4.72s\tremaining: 5.74s\n",
      "451:\tlearn: 0.0815991\ttotal: 4.73s\tremaining: 5.73s\n",
      "452:\tlearn: 0.0813906\ttotal: 4.74s\tremaining: 5.72s\n",
      "453:\tlearn: 0.0812367\ttotal: 4.75s\tremaining: 5.71s\n",
      "454:\tlearn: 0.0810584\ttotal: 4.76s\tremaining: 5.7s\n",
      "455:\tlearn: 0.0808963\ttotal: 4.77s\tremaining: 5.69s\n",
      "456:\tlearn: 0.0806936\ttotal: 4.78s\tremaining: 5.68s\n",
      "457:\tlearn: 0.0804469\ttotal: 4.79s\tremaining: 5.67s\n",
      "458:\tlearn: 0.0802668\ttotal: 4.8s\tremaining: 5.66s\n",
      "459:\tlearn: 0.0800579\ttotal: 4.81s\tremaining: 5.65s\n",
      "460:\tlearn: 0.0798683\ttotal: 4.82s\tremaining: 5.63s\n",
      "461:\tlearn: 0.0796994\ttotal: 4.83s\tremaining: 5.62s\n",
      "462:\tlearn: 0.0794576\ttotal: 4.84s\tremaining: 5.62s\n",
      "463:\tlearn: 0.0792280\ttotal: 4.85s\tremaining: 5.6s\n",
      "464:\tlearn: 0.0790100\ttotal: 4.86s\tremaining: 5.59s\n",
      "465:\tlearn: 0.0787749\ttotal: 4.87s\tremaining: 5.58s\n",
      "466:\tlearn: 0.0786194\ttotal: 4.88s\tremaining: 5.57s\n",
      "467:\tlearn: 0.0784986\ttotal: 4.89s\tremaining: 5.56s\n",
      "468:\tlearn: 0.0783454\ttotal: 4.9s\tremaining: 5.55s\n",
      "469:\tlearn: 0.0781646\ttotal: 4.91s\tremaining: 5.54s\n",
      "470:\tlearn: 0.0779561\ttotal: 4.92s\tremaining: 5.53s\n",
      "471:\tlearn: 0.0777530\ttotal: 4.93s\tremaining: 5.52s\n",
      "472:\tlearn: 0.0775544\ttotal: 4.94s\tremaining: 5.51s\n",
      "473:\tlearn: 0.0773522\ttotal: 4.95s\tremaining: 5.5s\n",
      "474:\tlearn: 0.0771388\ttotal: 4.96s\tremaining: 5.49s\n",
      "475:\tlearn: 0.0769565\ttotal: 4.97s\tremaining: 5.47s\n",
      "476:\tlearn: 0.0768512\ttotal: 4.98s\tremaining: 5.46s\n",
      "477:\tlearn: 0.0766588\ttotal: 4.99s\tremaining: 5.45s\n",
      "478:\tlearn: 0.0765000\ttotal: 5s\tremaining: 5.44s\n",
      "479:\tlearn: 0.0762932\ttotal: 5.01s\tremaining: 5.43s\n",
      "480:\tlearn: 0.0761506\ttotal: 5.02s\tremaining: 5.42s\n",
      "481:\tlearn: 0.0759620\ttotal: 5.03s\tremaining: 5.41s\n",
      "482:\tlearn: 0.0758066\ttotal: 5.04s\tremaining: 5.4s\n",
      "483:\tlearn: 0.0756552\ttotal: 5.05s\tremaining: 5.39s\n",
      "484:\tlearn: 0.0755564\ttotal: 5.07s\tremaining: 5.38s\n",
      "485:\tlearn: 0.0753561\ttotal: 5.08s\tremaining: 5.37s\n",
      "486:\tlearn: 0.0751073\ttotal: 5.09s\tremaining: 5.36s\n",
      "487:\tlearn: 0.0749376\ttotal: 5.1s\tremaining: 5.35s\n",
      "488:\tlearn: 0.0748160\ttotal: 5.11s\tremaining: 5.34s\n",
      "489:\tlearn: 0.0746483\ttotal: 5.12s\tremaining: 5.33s\n",
      "490:\tlearn: 0.0745318\ttotal: 5.13s\tremaining: 5.32s\n",
      "491:\tlearn: 0.0743736\ttotal: 5.14s\tremaining: 5.31s\n",
      "492:\tlearn: 0.0742498\ttotal: 5.15s\tremaining: 5.3s\n",
      "493:\tlearn: 0.0741544\ttotal: 5.16s\tremaining: 5.29s\n",
      "494:\tlearn: 0.0739917\ttotal: 5.17s\tremaining: 5.28s\n",
      "495:\tlearn: 0.0737714\ttotal: 5.18s\tremaining: 5.26s\n",
      "496:\tlearn: 0.0735694\ttotal: 5.19s\tremaining: 5.25s\n",
      "497:\tlearn: 0.0734318\ttotal: 5.2s\tremaining: 5.24s\n",
      "498:\tlearn: 0.0732831\ttotal: 5.21s\tremaining: 5.23s\n",
      "499:\tlearn: 0.0731199\ttotal: 5.22s\tremaining: 5.22s\n",
      "500:\tlearn: 0.0729477\ttotal: 5.23s\tremaining: 5.21s\n",
      "501:\tlearn: 0.0728002\ttotal: 5.24s\tremaining: 5.2s\n",
      "502:\tlearn: 0.0726681\ttotal: 5.25s\tremaining: 5.18s\n",
      "503:\tlearn: 0.0724959\ttotal: 5.26s\tremaining: 5.17s\n",
      "504:\tlearn: 0.0723147\ttotal: 5.27s\tremaining: 5.16s\n",
      "505:\tlearn: 0.0721818\ttotal: 5.28s\tremaining: 5.15s\n",
      "506:\tlearn: 0.0719835\ttotal: 5.29s\tremaining: 5.14s\n",
      "507:\tlearn: 0.0718110\ttotal: 5.3s\tremaining: 5.13s\n",
      "508:\tlearn: 0.0716160\ttotal: 5.31s\tremaining: 5.12s\n",
      "509:\tlearn: 0.0714685\ttotal: 5.32s\tremaining: 5.11s\n",
      "510:\tlearn: 0.0712917\ttotal: 5.33s\tremaining: 5.1s\n",
      "511:\tlearn: 0.0711139\ttotal: 5.34s\tremaining: 5.09s\n",
      "512:\tlearn: 0.0709341\ttotal: 5.35s\tremaining: 5.08s\n",
      "513:\tlearn: 0.0707799\ttotal: 5.36s\tremaining: 5.07s\n",
      "514:\tlearn: 0.0706151\ttotal: 5.37s\tremaining: 5.06s\n",
      "515:\tlearn: 0.0704233\ttotal: 5.38s\tremaining: 5.05s\n",
      "516:\tlearn: 0.0702926\ttotal: 5.39s\tremaining: 5.04s\n",
      "517:\tlearn: 0.0701337\ttotal: 5.4s\tremaining: 5.03s\n",
      "518:\tlearn: 0.0699581\ttotal: 5.41s\tremaining: 5.01s\n",
      "519:\tlearn: 0.0697718\ttotal: 5.42s\tremaining: 5s\n",
      "520:\tlearn: 0.0695942\ttotal: 5.43s\tremaining: 4.99s\n",
      "521:\tlearn: 0.0693875\ttotal: 5.44s\tremaining: 4.98s\n",
      "522:\tlearn: 0.0692275\ttotal: 5.45s\tremaining: 4.97s\n",
      "523:\tlearn: 0.0690202\ttotal: 5.46s\tremaining: 4.96s\n",
      "524:\tlearn: 0.0688961\ttotal: 5.47s\tremaining: 4.95s\n",
      "525:\tlearn: 0.0687375\ttotal: 5.48s\tremaining: 4.94s\n",
      "526:\tlearn: 0.0685476\ttotal: 5.49s\tremaining: 4.93s\n",
      "527:\tlearn: 0.0683963\ttotal: 5.5s\tremaining: 4.92s\n",
      "528:\tlearn: 0.0682247\ttotal: 5.51s\tremaining: 4.91s\n",
      "529:\tlearn: 0.0680822\ttotal: 5.52s\tremaining: 4.89s\n",
      "530:\tlearn: 0.0678958\ttotal: 5.53s\tremaining: 4.88s\n",
      "531:\tlearn: 0.0677260\ttotal: 5.54s\tremaining: 4.87s\n",
      "532:\tlearn: 0.0675993\ttotal: 5.55s\tremaining: 4.86s\n",
      "533:\tlearn: 0.0674610\ttotal: 5.56s\tremaining: 4.85s\n",
      "534:\tlearn: 0.0673681\ttotal: 5.57s\tremaining: 4.84s\n",
      "535:\tlearn: 0.0672308\ttotal: 5.58s\tremaining: 4.83s\n",
      "536:\tlearn: 0.0670887\ttotal: 5.59s\tremaining: 4.82s\n",
      "537:\tlearn: 0.0670027\ttotal: 5.6s\tremaining: 4.81s\n",
      "538:\tlearn: 0.0668824\ttotal: 5.61s\tremaining: 4.8s\n",
      "539:\tlearn: 0.0667388\ttotal: 5.62s\tremaining: 4.79s\n",
      "540:\tlearn: 0.0666237\ttotal: 5.63s\tremaining: 4.78s\n",
      "541:\tlearn: 0.0665099\ttotal: 5.64s\tremaining: 4.76s\n",
      "542:\tlearn: 0.0664272\ttotal: 5.65s\tremaining: 4.75s\n",
      "543:\tlearn: 0.0662565\ttotal: 5.66s\tremaining: 4.74s\n",
      "544:\tlearn: 0.0661314\ttotal: 5.67s\tremaining: 4.73s\n",
      "545:\tlearn: 0.0659684\ttotal: 5.68s\tremaining: 4.72s\n",
      "546:\tlearn: 0.0658273\ttotal: 5.69s\tremaining: 4.71s\n",
      "547:\tlearn: 0.0656431\ttotal: 5.7s\tremaining: 4.7s\n",
      "548:\tlearn: 0.0654920\ttotal: 5.71s\tremaining: 4.69s\n",
      "549:\tlearn: 0.0653070\ttotal: 5.72s\tremaining: 4.68s\n",
      "550:\tlearn: 0.0651465\ttotal: 5.73s\tremaining: 4.67s\n",
      "551:\tlearn: 0.0649979\ttotal: 5.74s\tremaining: 4.66s\n",
      "552:\tlearn: 0.0649141\ttotal: 5.75s\tremaining: 4.65s\n",
      "553:\tlearn: 0.0647683\ttotal: 5.76s\tremaining: 4.64s\n",
      "554:\tlearn: 0.0646173\ttotal: 5.77s\tremaining: 4.63s\n",
      "555:\tlearn: 0.0644821\ttotal: 5.78s\tremaining: 4.61s\n",
      "556:\tlearn: 0.0643451\ttotal: 5.79s\tremaining: 4.6s\n",
      "557:\tlearn: 0.0641703\ttotal: 5.8s\tremaining: 4.59s\n",
      "558:\tlearn: 0.0640198\ttotal: 5.81s\tremaining: 4.58s\n",
      "559:\tlearn: 0.0638830\ttotal: 5.82s\tremaining: 4.57s\n",
      "560:\tlearn: 0.0637454\ttotal: 5.83s\tremaining: 4.56s\n",
      "561:\tlearn: 0.0635971\ttotal: 5.84s\tremaining: 4.55s\n",
      "562:\tlearn: 0.0634519\ttotal: 5.85s\tremaining: 4.54s\n",
      "563:\tlearn: 0.0633386\ttotal: 5.86s\tremaining: 4.53s\n",
      "564:\tlearn: 0.0632071\ttotal: 5.87s\tremaining: 4.52s\n",
      "565:\tlearn: 0.0630750\ttotal: 5.88s\tremaining: 4.51s\n",
      "566:\tlearn: 0.0628949\ttotal: 5.89s\tremaining: 4.5s\n",
      "567:\tlearn: 0.0628103\ttotal: 5.9s\tremaining: 4.48s\n",
      "568:\tlearn: 0.0626447\ttotal: 5.91s\tremaining: 4.47s\n",
      "569:\tlearn: 0.0624759\ttotal: 5.92s\tremaining: 4.46s\n",
      "570:\tlearn: 0.0623818\ttotal: 5.92s\tremaining: 4.45s\n",
      "571:\tlearn: 0.0622654\ttotal: 5.93s\tremaining: 4.44s\n",
      "572:\tlearn: 0.0621445\ttotal: 5.95s\tremaining: 4.43s\n",
      "573:\tlearn: 0.0619948\ttotal: 5.96s\tremaining: 4.42s\n",
      "574:\tlearn: 0.0618782\ttotal: 5.97s\tremaining: 4.41s\n",
      "575:\tlearn: 0.0617484\ttotal: 5.98s\tremaining: 4.4s\n",
      "576:\tlearn: 0.0615925\ttotal: 5.99s\tremaining: 4.39s\n",
      "577:\tlearn: 0.0614357\ttotal: 6s\tremaining: 4.38s\n",
      "578:\tlearn: 0.0613357\ttotal: 6.01s\tremaining: 4.37s\n",
      "579:\tlearn: 0.0611832\ttotal: 6.02s\tremaining: 4.36s\n",
      "580:\tlearn: 0.0610362\ttotal: 6.03s\tremaining: 4.35s\n",
      "581:\tlearn: 0.0609195\ttotal: 6.04s\tremaining: 4.33s\n",
      "582:\tlearn: 0.0607842\ttotal: 6.05s\tremaining: 4.32s\n",
      "583:\tlearn: 0.0606402\ttotal: 6.06s\tremaining: 4.31s\n",
      "584:\tlearn: 0.0605808\ttotal: 6.07s\tremaining: 4.3s\n",
      "585:\tlearn: 0.0604289\ttotal: 6.08s\tremaining: 4.29s\n",
      "586:\tlearn: 0.0602816\ttotal: 6.09s\tremaining: 4.28s\n",
      "587:\tlearn: 0.0601635\ttotal: 6.1s\tremaining: 4.27s\n",
      "588:\tlearn: 0.0600244\ttotal: 6.11s\tremaining: 4.26s\n",
      "589:\tlearn: 0.0599301\ttotal: 6.12s\tremaining: 4.25s\n",
      "590:\tlearn: 0.0597954\ttotal: 6.13s\tremaining: 4.24s\n",
      "591:\tlearn: 0.0596327\ttotal: 6.14s\tremaining: 4.23s\n",
      "592:\tlearn: 0.0594682\ttotal: 6.15s\tremaining: 4.22s\n",
      "593:\tlearn: 0.0593292\ttotal: 6.16s\tremaining: 4.21s\n",
      "594:\tlearn: 0.0591920\ttotal: 6.17s\tremaining: 4.2s\n",
      "595:\tlearn: 0.0590441\ttotal: 6.18s\tremaining: 4.19s\n",
      "596:\tlearn: 0.0588821\ttotal: 6.19s\tremaining: 4.18s\n",
      "597:\tlearn: 0.0587330\ttotal: 6.2s\tremaining: 4.17s\n",
      "598:\tlearn: 0.0585948\ttotal: 6.21s\tremaining: 4.16s\n",
      "599:\tlearn: 0.0584467\ttotal: 6.22s\tremaining: 4.15s\n",
      "600:\tlearn: 0.0582935\ttotal: 6.23s\tremaining: 4.13s\n",
      "601:\tlearn: 0.0581664\ttotal: 6.24s\tremaining: 4.13s\n",
      "602:\tlearn: 0.0580404\ttotal: 6.25s\tremaining: 4.11s\n",
      "603:\tlearn: 0.0579096\ttotal: 6.26s\tremaining: 4.1s\n",
      "604:\tlearn: 0.0577638\ttotal: 6.27s\tremaining: 4.09s\n",
      "605:\tlearn: 0.0576150\ttotal: 6.28s\tremaining: 4.08s\n",
      "606:\tlearn: 0.0575092\ttotal: 6.29s\tremaining: 4.07s\n",
      "607:\tlearn: 0.0574450\ttotal: 6.3s\tremaining: 4.06s\n",
      "608:\tlearn: 0.0573197\ttotal: 6.31s\tremaining: 4.05s\n",
      "609:\tlearn: 0.0571742\ttotal: 6.32s\tremaining: 4.04s\n",
      "610:\tlearn: 0.0570295\ttotal: 6.33s\tremaining: 4.03s\n",
      "611:\tlearn: 0.0569017\ttotal: 6.34s\tremaining: 4.02s\n",
      "612:\tlearn: 0.0568256\ttotal: 6.35s\tremaining: 4.01s\n",
      "613:\tlearn: 0.0567004\ttotal: 6.36s\tremaining: 4s\n",
      "614:\tlearn: 0.0565754\ttotal: 6.37s\tremaining: 3.99s\n",
      "615:\tlearn: 0.0564911\ttotal: 6.38s\tremaining: 3.98s\n",
      "616:\tlearn: 0.0563438\ttotal: 6.39s\tremaining: 3.97s\n",
      "617:\tlearn: 0.0562031\ttotal: 6.4s\tremaining: 3.96s\n",
      "618:\tlearn: 0.0560672\ttotal: 6.41s\tremaining: 3.94s\n",
      "619:\tlearn: 0.0559157\ttotal: 6.42s\tremaining: 3.93s\n",
      "620:\tlearn: 0.0557733\ttotal: 6.43s\tremaining: 3.92s\n",
      "621:\tlearn: 0.0556752\ttotal: 6.44s\tremaining: 3.91s\n",
      "622:\tlearn: 0.0555992\ttotal: 6.45s\tremaining: 3.9s\n",
      "623:\tlearn: 0.0554732\ttotal: 6.46s\tremaining: 3.89s\n",
      "624:\tlearn: 0.0553579\ttotal: 6.47s\tremaining: 3.88s\n",
      "625:\tlearn: 0.0552269\ttotal: 6.48s\tremaining: 3.87s\n",
      "626:\tlearn: 0.0550815\ttotal: 6.49s\tremaining: 3.86s\n",
      "627:\tlearn: 0.0549800\ttotal: 6.5s\tremaining: 3.85s\n",
      "628:\tlearn: 0.0548864\ttotal: 6.51s\tremaining: 3.84s\n",
      "629:\tlearn: 0.0548057\ttotal: 6.52s\tremaining: 3.83s\n",
      "630:\tlearn: 0.0546651\ttotal: 6.53s\tremaining: 3.82s\n",
      "631:\tlearn: 0.0545350\ttotal: 6.54s\tremaining: 3.81s\n",
      "632:\tlearn: 0.0544496\ttotal: 6.55s\tremaining: 3.8s\n",
      "633:\tlearn: 0.0543485\ttotal: 6.56s\tremaining: 3.79s\n",
      "634:\tlearn: 0.0542047\ttotal: 6.57s\tremaining: 3.78s\n",
      "635:\tlearn: 0.0541361\ttotal: 6.58s\tremaining: 3.77s\n",
      "636:\tlearn: 0.0540210\ttotal: 6.59s\tremaining: 3.76s\n",
      "637:\tlearn: 0.0539193\ttotal: 6.6s\tremaining: 3.75s\n",
      "638:\tlearn: 0.0538155\ttotal: 6.61s\tremaining: 3.73s\n",
      "639:\tlearn: 0.0536853\ttotal: 6.62s\tremaining: 3.72s\n",
      "640:\tlearn: 0.0535841\ttotal: 6.63s\tremaining: 3.71s\n",
      "641:\tlearn: 0.0534642\ttotal: 6.64s\tremaining: 3.7s\n",
      "642:\tlearn: 0.0533333\ttotal: 6.65s\tremaining: 3.69s\n",
      "643:\tlearn: 0.0532526\ttotal: 6.66s\tremaining: 3.68s\n",
      "644:\tlearn: 0.0531202\ttotal: 6.67s\tremaining: 3.67s\n",
      "645:\tlearn: 0.0529977\ttotal: 6.68s\tremaining: 3.66s\n",
      "646:\tlearn: 0.0529203\ttotal: 6.69s\tremaining: 3.65s\n",
      "647:\tlearn: 0.0528057\ttotal: 6.7s\tremaining: 3.64s\n",
      "648:\tlearn: 0.0526792\ttotal: 6.71s\tremaining: 3.63s\n",
      "649:\tlearn: 0.0525507\ttotal: 6.72s\tremaining: 3.62s\n",
      "650:\tlearn: 0.0524436\ttotal: 6.73s\tremaining: 3.61s\n",
      "651:\tlearn: 0.0523165\ttotal: 6.74s\tremaining: 3.6s\n",
      "652:\tlearn: 0.0522037\ttotal: 6.75s\tremaining: 3.59s\n",
      "653:\tlearn: 0.0520558\ttotal: 6.76s\tremaining: 3.58s\n",
      "654:\tlearn: 0.0519292\ttotal: 6.77s\tremaining: 3.57s\n",
      "655:\tlearn: 0.0518036\ttotal: 6.79s\tremaining: 3.56s\n",
      "656:\tlearn: 0.0517052\ttotal: 6.8s\tremaining: 3.55s\n",
      "657:\tlearn: 0.0516149\ttotal: 6.81s\tremaining: 3.54s\n",
      "658:\tlearn: 0.0514919\ttotal: 6.82s\tremaining: 3.53s\n",
      "659:\tlearn: 0.0513824\ttotal: 6.83s\tremaining: 3.52s\n",
      "660:\tlearn: 0.0512504\ttotal: 6.84s\tremaining: 3.51s\n",
      "661:\tlearn: 0.0511395\ttotal: 6.85s\tremaining: 3.5s\n",
      "662:\tlearn: 0.0510333\ttotal: 6.86s\tremaining: 3.49s\n",
      "663:\tlearn: 0.0509216\ttotal: 6.87s\tremaining: 3.48s\n",
      "664:\tlearn: 0.0508463\ttotal: 6.88s\tremaining: 3.46s\n",
      "665:\tlearn: 0.0507454\ttotal: 6.89s\tremaining: 3.45s\n",
      "666:\tlearn: 0.0506156\ttotal: 6.9s\tremaining: 3.44s\n",
      "667:\tlearn: 0.0504986\ttotal: 6.91s\tremaining: 3.43s\n",
      "668:\tlearn: 0.0503891\ttotal: 6.92s\tremaining: 3.42s\n",
      "669:\tlearn: 0.0502597\ttotal: 6.93s\tremaining: 3.41s\n",
      "670:\tlearn: 0.0501674\ttotal: 6.94s\tremaining: 3.4s\n",
      "671:\tlearn: 0.0500574\ttotal: 6.95s\tremaining: 3.39s\n",
      "672:\tlearn: 0.0499981\ttotal: 6.96s\tremaining: 3.38s\n",
      "673:\tlearn: 0.0499219\ttotal: 6.97s\tremaining: 3.37s\n",
      "674:\tlearn: 0.0498054\ttotal: 6.98s\tremaining: 3.36s\n",
      "675:\tlearn: 0.0496682\ttotal: 6.99s\tremaining: 3.35s\n",
      "676:\tlearn: 0.0495679\ttotal: 7s\tremaining: 3.34s\n",
      "677:\tlearn: 0.0494902\ttotal: 7.01s\tremaining: 3.33s\n",
      "678:\tlearn: 0.0494073\ttotal: 7.02s\tremaining: 3.32s\n",
      "679:\tlearn: 0.0493189\ttotal: 7.03s\tremaining: 3.31s\n",
      "680:\tlearn: 0.0492206\ttotal: 7.04s\tremaining: 3.3s\n",
      "681:\tlearn: 0.0491224\ttotal: 7.05s\tremaining: 3.29s\n",
      "682:\tlearn: 0.0489890\ttotal: 7.06s\tremaining: 3.28s\n",
      "683:\tlearn: 0.0488802\ttotal: 7.07s\tremaining: 3.27s\n",
      "684:\tlearn: 0.0487833\ttotal: 7.08s\tremaining: 3.26s\n",
      "685:\tlearn: 0.0487024\ttotal: 7.09s\tremaining: 3.25s\n",
      "686:\tlearn: 0.0485806\ttotal: 7.1s\tremaining: 3.24s\n",
      "687:\tlearn: 0.0484569\ttotal: 7.11s\tremaining: 3.23s\n",
      "688:\tlearn: 0.0483303\ttotal: 7.12s\tremaining: 3.21s\n",
      "689:\tlearn: 0.0482422\ttotal: 7.13s\tremaining: 3.21s\n",
      "690:\tlearn: 0.0481184\ttotal: 7.14s\tremaining: 3.19s\n",
      "691:\tlearn: 0.0480262\ttotal: 7.15s\tremaining: 3.18s\n",
      "692:\tlearn: 0.0478800\ttotal: 7.16s\tremaining: 3.17s\n",
      "693:\tlearn: 0.0477666\ttotal: 7.17s\tremaining: 3.16s\n",
      "694:\tlearn: 0.0476633\ttotal: 7.18s\tremaining: 3.15s\n",
      "695:\tlearn: 0.0475882\ttotal: 7.19s\tremaining: 3.14s\n",
      "696:\tlearn: 0.0474990\ttotal: 7.2s\tremaining: 3.13s\n",
      "697:\tlearn: 0.0473899\ttotal: 7.21s\tremaining: 3.12s\n",
      "698:\tlearn: 0.0472906\ttotal: 7.22s\tremaining: 3.11s\n",
      "699:\tlearn: 0.0471768\ttotal: 7.24s\tremaining: 3.1s\n",
      "700:\tlearn: 0.0471281\ttotal: 7.24s\tremaining: 3.09s\n",
      "701:\tlearn: 0.0470556\ttotal: 7.25s\tremaining: 3.08s\n",
      "702:\tlearn: 0.0469511\ttotal: 7.26s\tremaining: 3.07s\n",
      "703:\tlearn: 0.0468756\ttotal: 7.27s\tremaining: 3.06s\n",
      "704:\tlearn: 0.0467783\ttotal: 7.28s\tremaining: 3.05s\n",
      "705:\tlearn: 0.0466951\ttotal: 7.29s\tremaining: 3.04s\n",
      "706:\tlearn: 0.0465800\ttotal: 7.3s\tremaining: 3.03s\n",
      "707:\tlearn: 0.0464628\ttotal: 7.31s\tremaining: 3.02s\n",
      "708:\tlearn: 0.0463392\ttotal: 7.32s\tremaining: 3.01s\n",
      "709:\tlearn: 0.0462483\ttotal: 7.33s\tremaining: 3s\n",
      "710:\tlearn: 0.0461699\ttotal: 7.34s\tremaining: 2.98s\n",
      "711:\tlearn: 0.0460768\ttotal: 7.35s\tremaining: 2.97s\n",
      "712:\tlearn: 0.0459719\ttotal: 7.36s\tremaining: 2.96s\n",
      "713:\tlearn: 0.0458610\ttotal: 7.37s\tremaining: 2.95s\n",
      "714:\tlearn: 0.0457748\ttotal: 7.39s\tremaining: 2.94s\n",
      "715:\tlearn: 0.0456719\ttotal: 7.4s\tremaining: 2.93s\n",
      "716:\tlearn: 0.0455701\ttotal: 7.41s\tremaining: 2.92s\n",
      "717:\tlearn: 0.0454658\ttotal: 7.42s\tremaining: 2.91s\n",
      "718:\tlearn: 0.0453825\ttotal: 7.42s\tremaining: 2.9s\n",
      "719:\tlearn: 0.0452786\ttotal: 7.43s\tremaining: 2.89s\n",
      "720:\tlearn: 0.0451487\ttotal: 7.45s\tremaining: 2.88s\n",
      "721:\tlearn: 0.0450635\ttotal: 7.46s\tremaining: 2.87s\n",
      "722:\tlearn: 0.0449808\ttotal: 7.46s\tremaining: 2.86s\n",
      "723:\tlearn: 0.0448659\ttotal: 7.47s\tremaining: 2.85s\n",
      "724:\tlearn: 0.0447578\ttotal: 7.49s\tremaining: 2.84s\n",
      "725:\tlearn: 0.0446357\ttotal: 7.5s\tremaining: 2.83s\n",
      "726:\tlearn: 0.0445205\ttotal: 7.5s\tremaining: 2.82s\n",
      "727:\tlearn: 0.0444394\ttotal: 7.51s\tremaining: 2.81s\n",
      "728:\tlearn: 0.0443249\ttotal: 7.53s\tremaining: 2.8s\n",
      "729:\tlearn: 0.0442315\ttotal: 7.54s\tremaining: 2.79s\n",
      "730:\tlearn: 0.0441463\ttotal: 7.54s\tremaining: 2.78s\n",
      "731:\tlearn: 0.0440270\ttotal: 7.55s\tremaining: 2.77s\n",
      "732:\tlearn: 0.0439243\ttotal: 7.57s\tremaining: 2.75s\n",
      "733:\tlearn: 0.0438047\ttotal: 7.57s\tremaining: 2.75s\n",
      "734:\tlearn: 0.0437210\ttotal: 7.58s\tremaining: 2.73s\n",
      "735:\tlearn: 0.0436143\ttotal: 7.6s\tremaining: 2.72s\n",
      "736:\tlearn: 0.0435284\ttotal: 7.61s\tremaining: 2.71s\n",
      "737:\tlearn: 0.0434511\ttotal: 7.62s\tremaining: 2.7s\n",
      "738:\tlearn: 0.0434176\ttotal: 7.62s\tremaining: 2.69s\n",
      "739:\tlearn: 0.0433693\ttotal: 7.63s\tremaining: 2.68s\n",
      "740:\tlearn: 0.0432612\ttotal: 7.64s\tremaining: 2.67s\n",
      "741:\tlearn: 0.0431883\ttotal: 7.65s\tremaining: 2.66s\n",
      "742:\tlearn: 0.0431298\ttotal: 7.66s\tremaining: 2.65s\n",
      "743:\tlearn: 0.0430294\ttotal: 7.67s\tremaining: 2.64s\n",
      "744:\tlearn: 0.0429566\ttotal: 7.68s\tremaining: 2.63s\n",
      "745:\tlearn: 0.0428933\ttotal: 7.69s\tremaining: 2.62s\n",
      "746:\tlearn: 0.0428197\ttotal: 7.7s\tremaining: 2.61s\n",
      "747:\tlearn: 0.0427177\ttotal: 7.71s\tremaining: 2.6s\n",
      "748:\tlearn: 0.0426043\ttotal: 7.72s\tremaining: 2.59s\n",
      "749:\tlearn: 0.0425015\ttotal: 7.73s\tremaining: 2.58s\n",
      "750:\tlearn: 0.0423925\ttotal: 7.74s\tremaining: 2.57s\n",
      "751:\tlearn: 0.0423142\ttotal: 7.75s\tremaining: 2.56s\n",
      "752:\tlearn: 0.0422408\ttotal: 7.76s\tremaining: 2.55s\n",
      "753:\tlearn: 0.0421531\ttotal: 7.77s\tremaining: 2.54s\n",
      "754:\tlearn: 0.0421060\ttotal: 7.78s\tremaining: 2.52s\n",
      "755:\tlearn: 0.0420025\ttotal: 7.79s\tremaining: 2.52s\n",
      "756:\tlearn: 0.0419113\ttotal: 7.8s\tremaining: 2.5s\n",
      "757:\tlearn: 0.0418193\ttotal: 7.81s\tremaining: 2.49s\n",
      "758:\tlearn: 0.0417142\ttotal: 7.82s\tremaining: 2.48s\n",
      "759:\tlearn: 0.0416078\ttotal: 7.83s\tremaining: 2.47s\n",
      "760:\tlearn: 0.0415011\ttotal: 7.84s\tremaining: 2.46s\n",
      "761:\tlearn: 0.0414138\ttotal: 7.85s\tremaining: 2.45s\n",
      "762:\tlearn: 0.0413129\ttotal: 7.86s\tremaining: 2.44s\n",
      "763:\tlearn: 0.0412412\ttotal: 7.88s\tremaining: 2.43s\n",
      "764:\tlearn: 0.0411940\ttotal: 7.88s\tremaining: 2.42s\n",
      "765:\tlearn: 0.0411351\ttotal: 7.89s\tremaining: 2.41s\n",
      "766:\tlearn: 0.0410305\ttotal: 7.9s\tremaining: 2.4s\n",
      "767:\tlearn: 0.0409402\ttotal: 7.91s\tremaining: 2.39s\n",
      "768:\tlearn: 0.0408306\ttotal: 7.92s\tremaining: 2.38s\n",
      "769:\tlearn: 0.0407493\ttotal: 7.93s\tremaining: 2.37s\n",
      "770:\tlearn: 0.0406704\ttotal: 7.94s\tremaining: 2.36s\n",
      "771:\tlearn: 0.0405765\ttotal: 7.95s\tremaining: 2.35s\n",
      "772:\tlearn: 0.0404823\ttotal: 7.96s\tremaining: 2.34s\n",
      "773:\tlearn: 0.0404196\ttotal: 7.97s\tremaining: 2.33s\n",
      "774:\tlearn: 0.0403247\ttotal: 7.98s\tremaining: 2.32s\n",
      "775:\tlearn: 0.0402245\ttotal: 7.99s\tremaining: 2.31s\n",
      "776:\tlearn: 0.0401338\ttotal: 8.01s\tremaining: 2.3s\n",
      "777:\tlearn: 0.0400324\ttotal: 8.02s\tremaining: 2.29s\n",
      "778:\tlearn: 0.0399685\ttotal: 8.03s\tremaining: 2.28s\n",
      "779:\tlearn: 0.0398910\ttotal: 8.04s\tremaining: 2.27s\n",
      "780:\tlearn: 0.0398335\ttotal: 8.04s\tremaining: 2.25s\n",
      "781:\tlearn: 0.0397778\ttotal: 8.05s\tremaining: 2.25s\n",
      "782:\tlearn: 0.0397067\ttotal: 8.06s\tremaining: 2.23s\n",
      "783:\tlearn: 0.0396210\ttotal: 8.07s\tremaining: 2.22s\n",
      "784:\tlearn: 0.0395418\ttotal: 8.08s\tremaining: 2.21s\n",
      "785:\tlearn: 0.0394424\ttotal: 8.1s\tremaining: 2.2s\n",
      "786:\tlearn: 0.0393590\ttotal: 8.11s\tremaining: 2.19s\n",
      "787:\tlearn: 0.0392620\ttotal: 8.12s\tremaining: 2.18s\n",
      "788:\tlearn: 0.0391676\ttotal: 8.13s\tremaining: 2.17s\n",
      "789:\tlearn: 0.0390844\ttotal: 8.13s\tremaining: 2.16s\n",
      "790:\tlearn: 0.0389867\ttotal: 8.14s\tremaining: 2.15s\n",
      "791:\tlearn: 0.0389200\ttotal: 8.15s\tremaining: 2.14s\n",
      "792:\tlearn: 0.0388597\ttotal: 8.16s\tremaining: 2.13s\n",
      "793:\tlearn: 0.0387902\ttotal: 8.18s\tremaining: 2.12s\n",
      "794:\tlearn: 0.0386979\ttotal: 8.19s\tremaining: 2.11s\n",
      "795:\tlearn: 0.0386226\ttotal: 8.2s\tremaining: 2.1s\n",
      "796:\tlearn: 0.0385240\ttotal: 8.21s\tremaining: 2.09s\n",
      "797:\tlearn: 0.0384498\ttotal: 8.22s\tremaining: 2.08s\n",
      "798:\tlearn: 0.0383672\ttotal: 8.23s\tremaining: 2.07s\n",
      "799:\tlearn: 0.0382860\ttotal: 8.24s\tremaining: 2.06s\n",
      "800:\tlearn: 0.0382285\ttotal: 8.25s\tremaining: 2.05s\n",
      "801:\tlearn: 0.0381593\ttotal: 8.26s\tremaining: 2.04s\n",
      "802:\tlearn: 0.0380671\ttotal: 8.27s\tremaining: 2.03s\n",
      "803:\tlearn: 0.0379803\ttotal: 8.28s\tremaining: 2.02s\n",
      "804:\tlearn: 0.0379123\ttotal: 8.29s\tremaining: 2.01s\n",
      "805:\tlearn: 0.0378200\ttotal: 8.3s\tremaining: 2s\n",
      "806:\tlearn: 0.0377542\ttotal: 8.31s\tremaining: 1.99s\n",
      "807:\tlearn: 0.0376737\ttotal: 8.32s\tremaining: 1.98s\n",
      "808:\tlearn: 0.0376117\ttotal: 8.33s\tremaining: 1.97s\n",
      "809:\tlearn: 0.0375448\ttotal: 8.34s\tremaining: 1.96s\n",
      "810:\tlearn: 0.0374918\ttotal: 8.35s\tremaining: 1.95s\n",
      "811:\tlearn: 0.0374164\ttotal: 8.36s\tremaining: 1.93s\n",
      "812:\tlearn: 0.0373145\ttotal: 8.37s\tremaining: 1.92s\n",
      "813:\tlearn: 0.0372201\ttotal: 8.38s\tremaining: 1.91s\n",
      "814:\tlearn: 0.0371403\ttotal: 8.39s\tremaining: 1.9s\n",
      "815:\tlearn: 0.0370493\ttotal: 8.4s\tremaining: 1.89s\n",
      "816:\tlearn: 0.0369768\ttotal: 8.41s\tremaining: 1.88s\n",
      "817:\tlearn: 0.0369018\ttotal: 8.42s\tremaining: 1.87s\n",
      "818:\tlearn: 0.0368164\ttotal: 8.43s\tremaining: 1.86s\n",
      "819:\tlearn: 0.0367626\ttotal: 8.44s\tremaining: 1.85s\n",
      "820:\tlearn: 0.0366987\ttotal: 8.45s\tremaining: 1.84s\n",
      "821:\tlearn: 0.0366334\ttotal: 8.46s\tremaining: 1.83s\n",
      "822:\tlearn: 0.0365619\ttotal: 8.47s\tremaining: 1.82s\n",
      "823:\tlearn: 0.0364990\ttotal: 8.48s\tremaining: 1.81s\n",
      "824:\tlearn: 0.0364005\ttotal: 8.49s\tremaining: 1.8s\n",
      "825:\tlearn: 0.0363383\ttotal: 8.5s\tremaining: 1.79s\n",
      "826:\tlearn: 0.0362632\ttotal: 8.51s\tremaining: 1.78s\n",
      "827:\tlearn: 0.0361752\ttotal: 8.52s\tremaining: 1.77s\n",
      "828:\tlearn: 0.0360874\ttotal: 8.53s\tremaining: 1.76s\n",
      "829:\tlearn: 0.0360104\ttotal: 8.55s\tremaining: 1.75s\n",
      "830:\tlearn: 0.0359356\ttotal: 8.56s\tremaining: 1.74s\n",
      "831:\tlearn: 0.0358572\ttotal: 8.59s\tremaining: 1.74s\n",
      "832:\tlearn: 0.0357715\ttotal: 8.62s\tremaining: 1.73s\n",
      "833:\tlearn: 0.0356867\ttotal: 8.63s\tremaining: 1.72s\n",
      "834:\tlearn: 0.0355841\ttotal: 8.65s\tremaining: 1.71s\n",
      "835:\tlearn: 0.0354930\ttotal: 8.67s\tremaining: 1.7s\n",
      "836:\tlearn: 0.0354139\ttotal: 8.68s\tremaining: 1.69s\n",
      "837:\tlearn: 0.0353255\ttotal: 8.69s\tremaining: 1.68s\n",
      "838:\tlearn: 0.0352852\ttotal: 8.7s\tremaining: 1.67s\n",
      "839:\tlearn: 0.0352216\ttotal: 8.71s\tremaining: 1.66s\n",
      "840:\tlearn: 0.0351519\ttotal: 8.73s\tremaining: 1.65s\n",
      "841:\tlearn: 0.0350894\ttotal: 8.74s\tremaining: 1.64s\n",
      "842:\tlearn: 0.0350467\ttotal: 8.75s\tremaining: 1.63s\n",
      "843:\tlearn: 0.0349832\ttotal: 8.76s\tremaining: 1.62s\n",
      "844:\tlearn: 0.0349380\ttotal: 8.77s\tremaining: 1.61s\n",
      "845:\tlearn: 0.0348653\ttotal: 8.78s\tremaining: 1.6s\n",
      "846:\tlearn: 0.0347782\ttotal: 8.79s\tremaining: 1.59s\n",
      "847:\tlearn: 0.0346867\ttotal: 8.8s\tremaining: 1.58s\n",
      "848:\tlearn: 0.0346118\ttotal: 8.81s\tremaining: 1.57s\n",
      "849:\tlearn: 0.0345446\ttotal: 8.82s\tremaining: 1.56s\n",
      "850:\tlearn: 0.0344794\ttotal: 8.84s\tremaining: 1.55s\n",
      "851:\tlearn: 0.0344168\ttotal: 8.85s\tremaining: 1.54s\n",
      "852:\tlearn: 0.0343288\ttotal: 8.9s\tremaining: 1.53s\n",
      "853:\tlearn: 0.0342514\ttotal: 8.91s\tremaining: 1.52s\n",
      "854:\tlearn: 0.0342037\ttotal: 8.93s\tremaining: 1.51s\n",
      "855:\tlearn: 0.0341235\ttotal: 8.94s\tremaining: 1.5s\n",
      "856:\tlearn: 0.0340692\ttotal: 8.95s\tremaining: 1.49s\n",
      "857:\tlearn: 0.0340203\ttotal: 8.96s\tremaining: 1.48s\n",
      "858:\tlearn: 0.0339443\ttotal: 8.97s\tremaining: 1.47s\n",
      "859:\tlearn: 0.0338848\ttotal: 8.98s\tremaining: 1.46s\n",
      "860:\tlearn: 0.0337900\ttotal: 8.99s\tremaining: 1.45s\n",
      "861:\tlearn: 0.0337262\ttotal: 9s\tremaining: 1.44s\n",
      "862:\tlearn: 0.0336456\ttotal: 9.01s\tremaining: 1.43s\n",
      "863:\tlearn: 0.0336069\ttotal: 9.02s\tremaining: 1.42s\n",
      "864:\tlearn: 0.0335332\ttotal: 9.03s\tremaining: 1.41s\n",
      "865:\tlearn: 0.0334791\ttotal: 9.04s\tremaining: 1.4s\n",
      "866:\tlearn: 0.0334117\ttotal: 9.05s\tremaining: 1.39s\n",
      "867:\tlearn: 0.0333400\ttotal: 9.06s\tremaining: 1.38s\n",
      "868:\tlearn: 0.0332802\ttotal: 9.07s\tremaining: 1.37s\n",
      "869:\tlearn: 0.0332081\ttotal: 9.08s\tremaining: 1.36s\n",
      "870:\tlearn: 0.0331343\ttotal: 9.09s\tremaining: 1.35s\n",
      "871:\tlearn: 0.0330470\ttotal: 9.1s\tremaining: 1.34s\n",
      "872:\tlearn: 0.0329923\ttotal: 9.11s\tremaining: 1.32s\n",
      "873:\tlearn: 0.0329166\ttotal: 9.12s\tremaining: 1.31s\n",
      "874:\tlearn: 0.0328394\ttotal: 9.13s\tremaining: 1.3s\n",
      "875:\tlearn: 0.0327679\ttotal: 9.15s\tremaining: 1.29s\n",
      "876:\tlearn: 0.0327072\ttotal: 9.16s\tremaining: 1.28s\n",
      "877:\tlearn: 0.0326469\ttotal: 9.17s\tremaining: 1.27s\n",
      "878:\tlearn: 0.0325731\ttotal: 9.18s\tremaining: 1.26s\n",
      "879:\tlearn: 0.0325034\ttotal: 9.19s\tremaining: 1.25s\n",
      "880:\tlearn: 0.0324130\ttotal: 9.2s\tremaining: 1.24s\n",
      "881:\tlearn: 0.0323242\ttotal: 9.21s\tremaining: 1.23s\n",
      "882:\tlearn: 0.0322430\ttotal: 9.22s\tremaining: 1.22s\n",
      "883:\tlearn: 0.0321815\ttotal: 9.23s\tremaining: 1.21s\n",
      "884:\tlearn: 0.0321181\ttotal: 9.24s\tremaining: 1.2s\n",
      "885:\tlearn: 0.0320643\ttotal: 9.25s\tremaining: 1.19s\n",
      "886:\tlearn: 0.0320055\ttotal: 9.26s\tremaining: 1.18s\n",
      "887:\tlearn: 0.0319330\ttotal: 9.27s\tremaining: 1.17s\n",
      "888:\tlearn: 0.0318721\ttotal: 9.28s\tremaining: 1.16s\n",
      "889:\tlearn: 0.0317935\ttotal: 9.29s\tremaining: 1.15s\n",
      "890:\tlearn: 0.0317531\ttotal: 9.3s\tremaining: 1.14s\n",
      "891:\tlearn: 0.0317096\ttotal: 9.31s\tremaining: 1.13s\n",
      "892:\tlearn: 0.0316446\ttotal: 9.32s\tremaining: 1.12s\n",
      "893:\tlearn: 0.0315725\ttotal: 9.33s\tremaining: 1.11s\n",
      "894:\tlearn: 0.0314815\ttotal: 9.34s\tremaining: 1.1s\n",
      "895:\tlearn: 0.0314231\ttotal: 9.35s\tremaining: 1.08s\n",
      "896:\tlearn: 0.0313592\ttotal: 9.36s\tremaining: 1.07s\n",
      "897:\tlearn: 0.0313246\ttotal: 9.37s\tremaining: 1.06s\n",
      "898:\tlearn: 0.0312542\ttotal: 9.38s\tremaining: 1.05s\n",
      "899:\tlearn: 0.0311825\ttotal: 9.39s\tremaining: 1.04s\n",
      "900:\tlearn: 0.0311475\ttotal: 9.4s\tremaining: 1.03s\n",
      "901:\tlearn: 0.0310712\ttotal: 9.41s\tremaining: 1.02s\n",
      "902:\tlearn: 0.0310103\ttotal: 9.43s\tremaining: 1.01s\n",
      "903:\tlearn: 0.0309573\ttotal: 9.44s\tremaining: 1s\n",
      "904:\tlearn: 0.0309060\ttotal: 9.45s\tremaining: 992ms\n",
      "905:\tlearn: 0.0308321\ttotal: 9.46s\tremaining: 981ms\n",
      "906:\tlearn: 0.0307713\ttotal: 9.47s\tremaining: 971ms\n",
      "907:\tlearn: 0.0307059\ttotal: 9.48s\tremaining: 960ms\n",
      "908:\tlearn: 0.0306421\ttotal: 9.49s\tremaining: 950ms\n",
      "909:\tlearn: 0.0305898\ttotal: 9.5s\tremaining: 940ms\n",
      "910:\tlearn: 0.0305251\ttotal: 9.51s\tremaining: 929ms\n",
      "911:\tlearn: 0.0304817\ttotal: 9.52s\tremaining: 919ms\n",
      "912:\tlearn: 0.0304066\ttotal: 9.53s\tremaining: 909ms\n",
      "913:\tlearn: 0.0303510\ttotal: 9.54s\tremaining: 898ms\n",
      "914:\tlearn: 0.0302909\ttotal: 9.55s\tremaining: 888ms\n",
      "915:\tlearn: 0.0302308\ttotal: 9.57s\tremaining: 877ms\n",
      "916:\tlearn: 0.0301771\ttotal: 9.58s\tremaining: 867ms\n",
      "917:\tlearn: 0.0301045\ttotal: 9.59s\tremaining: 856ms\n",
      "918:\tlearn: 0.0300312\ttotal: 9.6s\tremaining: 846ms\n",
      "919:\tlearn: 0.0299993\ttotal: 9.61s\tremaining: 836ms\n",
      "920:\tlearn: 0.0299488\ttotal: 9.62s\tremaining: 825ms\n",
      "921:\tlearn: 0.0298938\ttotal: 9.63s\tremaining: 815ms\n",
      "922:\tlearn: 0.0298239\ttotal: 9.64s\tremaining: 804ms\n",
      "923:\tlearn: 0.0297635\ttotal: 9.65s\tremaining: 794ms\n",
      "924:\tlearn: 0.0296939\ttotal: 9.66s\tremaining: 783ms\n",
      "925:\tlearn: 0.0296316\ttotal: 9.67s\tremaining: 773ms\n",
      "926:\tlearn: 0.0295665\ttotal: 9.68s\tremaining: 763ms\n",
      "927:\tlearn: 0.0295109\ttotal: 9.69s\tremaining: 752ms\n",
      "928:\tlearn: 0.0294513\ttotal: 9.71s\tremaining: 742ms\n",
      "929:\tlearn: 0.0293851\ttotal: 9.71s\tremaining: 731ms\n",
      "930:\tlearn: 0.0293668\ttotal: 9.72s\tremaining: 721ms\n",
      "931:\tlearn: 0.0293242\ttotal: 9.73s\tremaining: 710ms\n",
      "932:\tlearn: 0.0292689\ttotal: 9.74s\tremaining: 700ms\n",
      "933:\tlearn: 0.0292143\ttotal: 9.76s\tremaining: 689ms\n",
      "934:\tlearn: 0.0291887\ttotal: 9.77s\tremaining: 679ms\n",
      "935:\tlearn: 0.0291468\ttotal: 9.78s\tremaining: 668ms\n",
      "936:\tlearn: 0.0290924\ttotal: 9.79s\tremaining: 658ms\n",
      "937:\tlearn: 0.0290872\ttotal: 9.8s\tremaining: 648ms\n",
      "938:\tlearn: 0.0290306\ttotal: 9.81s\tremaining: 637ms\n",
      "939:\tlearn: 0.0289563\ttotal: 9.82s\tremaining: 627ms\n",
      "940:\tlearn: 0.0288831\ttotal: 9.83s\tremaining: 616ms\n",
      "941:\tlearn: 0.0288353\ttotal: 9.84s\tremaining: 606ms\n",
      "942:\tlearn: 0.0287932\ttotal: 9.85s\tremaining: 595ms\n",
      "943:\tlearn: 0.0287294\ttotal: 9.86s\tremaining: 585ms\n",
      "944:\tlearn: 0.0286788\ttotal: 9.87s\tremaining: 575ms\n",
      "945:\tlearn: 0.0286088\ttotal: 9.88s\tremaining: 564ms\n",
      "946:\tlearn: 0.0285701\ttotal: 9.89s\tremaining: 554ms\n",
      "947:\tlearn: 0.0285017\ttotal: 9.9s\tremaining: 543ms\n",
      "948:\tlearn: 0.0284517\ttotal: 9.91s\tremaining: 533ms\n",
      "949:\tlearn: 0.0283902\ttotal: 9.93s\tremaining: 522ms\n",
      "950:\tlearn: 0.0283304\ttotal: 9.94s\tremaining: 512ms\n",
      "951:\tlearn: 0.0282525\ttotal: 9.95s\tremaining: 502ms\n",
      "952:\tlearn: 0.0281898\ttotal: 9.96s\tremaining: 491ms\n",
      "953:\tlearn: 0.0281298\ttotal: 9.97s\tremaining: 481ms\n",
      "954:\tlearn: 0.0280863\ttotal: 9.98s\tremaining: 470ms\n",
      "955:\tlearn: 0.0280419\ttotal: 9.99s\tremaining: 460ms\n",
      "956:\tlearn: 0.0279959\ttotal: 10s\tremaining: 449ms\n",
      "957:\tlearn: 0.0279486\ttotal: 10s\tremaining: 439ms\n",
      "958:\tlearn: 0.0278874\ttotal: 10s\tremaining: 428ms\n",
      "959:\tlearn: 0.0278367\ttotal: 10s\tremaining: 418ms\n",
      "960:\tlearn: 0.0277609\ttotal: 10s\tremaining: 408ms\n",
      "961:\tlearn: 0.0276922\ttotal: 10.1s\tremaining: 397ms\n",
      "962:\tlearn: 0.0276358\ttotal: 10.1s\tremaining: 387ms\n",
      "963:\tlearn: 0.0275815\ttotal: 10.1s\tremaining: 376ms\n",
      "964:\tlearn: 0.0275181\ttotal: 10.1s\tremaining: 366ms\n",
      "965:\tlearn: 0.0274692\ttotal: 10.1s\tremaining: 355ms\n",
      "966:\tlearn: 0.0274359\ttotal: 10.1s\tremaining: 345ms\n",
      "967:\tlearn: 0.0273750\ttotal: 10.1s\tremaining: 334ms\n",
      "968:\tlearn: 0.0273356\ttotal: 10.1s\tremaining: 324ms\n",
      "969:\tlearn: 0.0272748\ttotal: 10.1s\tremaining: 314ms\n",
      "970:\tlearn: 0.0272642\ttotal: 10.1s\tremaining: 303ms\n",
      "971:\tlearn: 0.0272239\ttotal: 10.2s\tremaining: 293ms\n",
      "972:\tlearn: 0.0271717\ttotal: 10.2s\tremaining: 282ms\n",
      "973:\tlearn: 0.0271232\ttotal: 10.2s\tremaining: 272ms\n",
      "974:\tlearn: 0.0270711\ttotal: 10.2s\tremaining: 261ms\n",
      "975:\tlearn: 0.0269962\ttotal: 10.2s\tremaining: 251ms\n",
      "976:\tlearn: 0.0269381\ttotal: 10.2s\tremaining: 240ms\n",
      "977:\tlearn: 0.0268887\ttotal: 10.2s\tremaining: 230ms\n",
      "978:\tlearn: 0.0268444\ttotal: 10.2s\tremaining: 220ms\n",
      "979:\tlearn: 0.0268102\ttotal: 10.2s\tremaining: 209ms\n",
      "980:\tlearn: 0.0267500\ttotal: 10.3s\tremaining: 199ms\n",
      "981:\tlearn: 0.0267157\ttotal: 10.3s\tremaining: 188ms\n",
      "982:\tlearn: 0.0266542\ttotal: 10.3s\tremaining: 178ms\n",
      "983:\tlearn: 0.0265921\ttotal: 10.3s\tremaining: 167ms\n",
      "984:\tlearn: 0.0265629\ttotal: 10.3s\tremaining: 157ms\n",
      "985:\tlearn: 0.0265080\ttotal: 10.3s\tremaining: 146ms\n",
      "986:\tlearn: 0.0264535\ttotal: 10.3s\tremaining: 136ms\n",
      "987:\tlearn: 0.0264025\ttotal: 10.3s\tremaining: 126ms\n",
      "988:\tlearn: 0.0263388\ttotal: 10.3s\tremaining: 115ms\n",
      "989:\tlearn: 0.0262812\ttotal: 10.4s\tremaining: 105ms\n",
      "990:\tlearn: 0.0262140\ttotal: 10.4s\tremaining: 94.1ms\n",
      "991:\tlearn: 0.0261698\ttotal: 10.4s\tremaining: 83.7ms\n",
      "992:\tlearn: 0.0261475\ttotal: 10.4s\tremaining: 73.2ms\n",
      "993:\tlearn: 0.0260804\ttotal: 10.4s\tremaining: 62.7ms\n",
      "994:\tlearn: 0.0260185\ttotal: 10.4s\tremaining: 52.3ms\n",
      "995:\tlearn: 0.0259845\ttotal: 10.4s\tremaining: 41.8ms\n",
      "996:\tlearn: 0.0259232\ttotal: 10.4s\tremaining: 31.4ms\n",
      "997:\tlearn: 0.0258705\ttotal: 10.4s\tremaining: 20.9ms\n",
      "998:\tlearn: 0.0258100\ttotal: 10.4s\tremaining: 10.5ms\n",
      "999:\tlearn: 0.0257771\ttotal: 10.5s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x16be4dff0>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ce391236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9477332759977711, 0.95719908166612)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,model.predict(X_test)),accuracy_score(y_test,model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1c0df795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "831548e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.890159719572282, 0.9096425057395867)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,lr.predict(X_test)),accuracy_score(y_test,lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c6b15b",
   "metadata": {},
   "source": [
    "BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c350820",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification,AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b66edcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "125e240e3a1e4cf8a62bcce5b0b0470a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification LOAD REPORT from: bert-base-uncased\n",
      "Key                                        | Status     | \n",
      "-------------------------------------------+------------+-\n",
      "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED | \n",
      "cls.predictions.transform.LayerNorm.weight | UNEXPECTED | \n",
      "cls.predictions.transform.dense.weight     | UNEXPECTED | \n",
      "cls.seq_relationship.weight                | UNEXPECTED | \n",
      "cls.seq_relationship.bias                  | UNEXPECTED | \n",
      "cls.predictions.transform.dense.bias       | UNEXPECTED | \n",
      "cls.predictions.bias                       | UNEXPECTED | \n",
      "classifier.bias                            | MISSING    | \n",
      "classifier.weight                          | MISSING    | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"bert-base-uncased\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint,num_labels=len(set(df.target.to_list())))\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3aef714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(df.text.to_list(),df.target.to_list(),test_size=0.3,stratify=df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77568161",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(\n",
    "    X_train,\n",
    "    padding=True, \n",
    "    return_tensors=\"pt\",\n",
    "    truncation=True,\n",
    "    max_length = 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94d8c50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encodings = tokenizer(\n",
    "    X_test,\n",
    "    padding=True, \n",
    "    return_tensors=\"pt\",\n",
    "    truncation=True,\n",
    "    max_length = 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e4362b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f49bee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(train_encodings, y_train)\n",
    "test_dataset   = TextDataset(test_encodings, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9e7e8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    learning_rate=1e-3,   # ВАЖНО: выше, чем обычно\n",
    "    num_train_epochs=5,   # можно больше эпох\n",
    "    per_device_train_batch_size=16,\n",
    "    eval_strategy=\"epoch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57ec6c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1d7faab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "653b092c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/55/w3_kxcgn3k16y1sr65pd4hx00000gn/T/ipykernel_97090/2978824758.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/trainer.py:2174\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2172\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2175\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2179\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/trainer.py:2536\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2529\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2530\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2531\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2532\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2533\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2534\u001b[0m )\n\u001b[1;32m   2535\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2536\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2539\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2540\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2541\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2542\u001b[0m ):\n\u001b[1;32m   2543\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2544\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/trainer.py:3809\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3808\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3809\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3811\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3813\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3815\u001b[0m ):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/trainer.py:3880\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3878\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[1;32m   3879\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m-> 3880\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3882\u001b[0m \u001b[38;5;66;03m# User-defined compute_loss function\u001b[39;00m\n\u001b[1;32m   3883\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/utils/generic.py:835\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    834\u001b[0m     return_dict \u001b[38;5;241m=\u001b[39m return_dict_passed\n\u001b[0;32m--> 835\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    837\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1162\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, labels, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;129m@can_return_tuple\u001b[39m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;129m@auto_docstring\u001b[39m\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1154\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Unpack[TransformersKwargs],\n\u001b[1;32m   1155\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m|\u001b[39m SequenceClassifierOutput:\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m \u001b[38;5;124;03m    labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;124;03m        Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1159\u001b[0m \u001b[38;5;124;03m        config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1160\u001b[0m \u001b[38;5;124;03m        `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1162\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1167\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1172\u001b[0m     pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1174\u001b[0m     pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/utils/generic.py:1002\u001b[0m, in \u001b[0;36mcheck_model_inputs.<locals>.wrapped_fn.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m             outputs \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1001\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1002\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m original_exception:\n\u001b[1;32m   1004\u001b[0m     \u001b[38;5;66;03m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[39;00m\n\u001b[1;32m   1005\u001b[0m     \u001b[38;5;66;03m# Get a TypeError even after removing the recordable kwargs -> re-raise the original exception\u001b[39;00m\n\u001b[1;32m   1006\u001b[0m     \u001b[38;5;66;03m# Otherwise -> we're probably missing `**kwargs` in the decorated function\u001b[39;00m\n\u001b[1;32m   1007\u001b[0m     kwargs_without_recordable \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m recordable_keys}\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:696\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    679\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    680\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    681\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    684\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    685\u001b[0m )\n\u001b[1;32m    687\u001b[0m attention_mask, encoder_attention_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_attention_masks(\n\u001b[1;32m    688\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m    689\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    693\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m    694\u001b[0m )\n\u001b[0;32m--> 696\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[1;32m    708\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:452\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    442\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Unpack[TransformersKwargs],\n\u001b[1;32m    450\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m|\u001b[39m BaseModelOutputWithPastAndCrossAttentions:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, layer_module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer):\n\u001b[0;32m--> 452\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[1;32m    456\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m BaseModelOutputWithPastAndCrossAttentions(\n\u001b[1;32m    463\u001b[0m         last_hidden_state\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[1;32m    464\u001b[0m         past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    465\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/modeling_layers.py:93\u001b[0m, in \u001b[0;36mGradientCheckpointingLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning_once(message)\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m---> 93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:423\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m     cross_attention_output, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrossattention(\n\u001b[1;32m    414\u001b[0m         self_attention_output,\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# attention_mask\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    420\u001b[0m     )\n\u001b[1;32m    421\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m cross_attention_output\n\u001b[0;32m--> 423\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/pytorch_utils.py:201\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 201\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:429\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m--> 429\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    430\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:349\u001b[0m, in \u001b[0;36mBertIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    348\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[0;32m--> 349\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate_act_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/activations.py:89\u001b[0m, in \u001b[0;36mGELUActivation.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b8e082",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
